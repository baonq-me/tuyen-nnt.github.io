<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>My Blog</title>
    <description>Grow yourself and develop with me!</description>
    <link>http://localhost:5000/</link>
    <atom:link href="http://localhost:5000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 11 Sep 2021 00:20:30 +0700</pubDate>
    <lastBuildDate>Sat, 11 Sep 2021 00:20:30 +0700</lastBuildDate>
    <generator>Jekyll v3.9.0</generator>
    
      <item>
        <title>Data Analysis</title>
        <description>
&lt;ul&gt;
  &lt;li&gt;Tìm data phù hợp rồi collect nó&lt;/li&gt;
  &lt;li&gt;Đọc data trong môi trường dev&lt;/li&gt;
  &lt;li&gt;Chuẩn bị phân tích bằng cách cleaning và validation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;1-reading-data&quot;&gt;1. Reading data&lt;/h2&gt;

&lt;p&gt;Dùng pandas để đọc các format phổ biến như CSV, Excel, HDF5,…&lt;/p&gt;

&lt;h2 id=&quot;2-columns-và-rows&quot;&gt;2. Columns và Rows&lt;/h2&gt;
&lt;p&gt;####df.shape&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;in ra (n, m) với n là số row và m là số column&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;####df.columns&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;in ra list các column ở định dạng string&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Dataframe giống như Dictionary khi variable name là key (tên cột) còn các giá trị trong row là values. Do đó bạn có thể select column dùng &lt;code&gt;df[&quot;key&quot;]&lt;/code&gt;. Kết quả là 1 &lt;strong&gt;Series&lt;/strong&gt; các value của cột đó. Dtype của nó là &lt;code&gt;float64&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;**Lưu ý: NaN là là giá trị đặc biệt chỉ định value không hợp lệ hoặc bị thiếu. **&lt;/p&gt;

&lt;h2 id=&quot;3-clean-và-validate&quot;&gt;3. Clean và Validate&lt;/h2&gt;

&lt;p&gt;Đây là bảng data chứa cân nặng của baby ta dùng trong các ví dụ sắp tới:
&lt;img src=&quot;img/example-data.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Đầu tiên ta rút trích mỗi cột mà ta muốn phân tích lưu vào 1 biến:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;pounds= df[&quot;tên cột&quot;]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ounces= df[&quot;tên cột&quot;]&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ta xem có value gì xuất hiện trong cột mà ta muốn phân tích và mỗi value xuất hiện bao nhiêu lần:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;pounds.value_counts().sort_index()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/value-count.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Mặc định kết quả sort theo giá trị nào gặp nhiều nhất. Nên ta thêm &lt;code&gt;sort_index()&lt;/code&gt; để nó sort theo giá trị.&lt;/p&gt;

&lt;p&gt;=&amp;gt; Sau đó ta quay lại xem bảng data ban đầu để thấy sự hợp lý. Ta có thể kết luận data này đúng và chúng ta đang phân tích đúng.&lt;/p&gt;

&lt;h4 id=&quot;seriesdescribe&quot;&gt;Series.Describe()&lt;/h4&gt;
&lt;p&gt;Ta cũng có thể dùng attribute describe để có bảng thống kê mean, phương sai, min và max rồi kết luận như trên.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;pounds.describe()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/describe.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Giải thích bảng trên:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;50% : giá trị trung vị =7&lt;/li&gt;
  &lt;li&gt;mean: trung bình =8, do có chứa các giá trị đặc biệt ít gặp như quá cao hay quá thấp nên không có ý nghĩa lắm.
Do vậy, trước khi đưa vào tính toán mean thực sự, ta phải thay thế những giá trị đặc biệt trên bằng NaN (thuộc thư viện numpy) để nó có nghĩa là data này bị mất đi giúp không ảnh hưởng đến số liệu phân tích chung của chúng ta.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;seriesreplace&quot;&gt;Series.Replace()&lt;/h4&gt;

&lt;p&gt;Tham số đầu tiên là list các giá trị ta muốn replace.&lt;/p&gt;

&lt;p&gt;Tham số thứ 2 là giá trị mà ta muốn được replace thành.&lt;/p&gt;

&lt;p&gt;Tham số thứ 3 tùy chọn là &lt;code&gt;inplace=True&lt;/code&gt;, mặc định không đề cập thì là False. True nghĩa là thay thế series cũ, false là tạo mới series sau khi thay thế.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/replace-data.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Trả về kiểu dữ liệu series. Nếu inplace=True thì không cần gán vào biến mới.
Ta nhận thấy sau khi thay thế dữ liệu, mean() của series sẽ thay đổi.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;arithmetic-với-series&quot;&gt;Arithmetic với Series&lt;/h4&gt;
&lt;p&gt;Tùy nhu cầu của bạn muốn tính toán hay combine giá trị của các cột với nhau. Ở ví dụ bài học này, ta sẽ cộng pounds và ounces lại với nhau.&lt;/p&gt;

&lt;p&gt;Đầu tiên ta phải đổi giá trị ounces thành pounds bằng cách chia 16 (cách đổi đơn vị cân nặng).&lt;/p&gt;

&lt;p&gt;Sau đó ta cộng lại. Kết quả trả về là 1 series là tổng giá trị của 2 series pounds và ounces.&lt;/p&gt;

&lt;p&gt;Đến đây ta có thể đưa kết luận giá trị trung bình của 1 đặc tính như cân nặng trong dataset bằng &lt;code&gt;series.describe()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/arithmetic-data.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-filter-và-visualize-data&quot;&gt;4. Filter và Visualize data&lt;/h2&gt;

&lt;h4 id=&quot;histogram&quot;&gt;Histogram&lt;/h4&gt;
&lt;p&gt;Dùng để biểu thị tần suất xuất hiện của giá trị trong dataset. Để dùng biểu đồ này trong python, ta dùng thư viện &lt;code&gt;matplotlib&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/hist-analysis.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Tham số thứ 1 là series. Do histogram không nhận giá trị NaN nên chúng ta phải dùng hàm &lt;code&gt;dropna()&lt;/code&gt; để loại bỏ nó trong series.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tham số thứ 2 là bin. Số Bin nói với hist là nó muốn chia giá trị trên biểu đồ thành bao nhiêu interval (có thể hiểu là cột theo cân nặng đối với ví dụ) và đếm có bao nhiêu values trong dataset ứng với mỗi bin đó.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ngoài ra còn các thông số tùy chọn khác xem thêm tại đây: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html&lt;/p&gt;

&lt;p&gt;Quan sát biểu đồ hình trên, ta có thể thấy tần suất baby có cân nặng nhẹ xuất hiện nhiều hơn.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Ta thấy điều này hợp lý vì trong dataset có chứa dữ liệu các em bé sinh non có số tuần mang thai &amp;lt; 37 tuần.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;=&amp;gt; Theo đó, ta tiếp tục rút trích dữ liệu của cột chứa số tuần của baby.&lt;/p&gt;

&lt;p&gt;Để xem những em bé nào sinh non, ta dùng Boolean Series.&lt;/p&gt;

&lt;h4 id=&quot;boolean-series&quot;&gt;Boolean Series&lt;/h4&gt;
&lt;p&gt;Trả về series gồm các giá trị True hoặc False cho điều kiện mà ta áp dụng.&lt;/p&gt;

&lt;p&gt;Ta gán biểu thức gồm series của cột và điều kiện để trả về series chứa True và False:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;preterm = df[&quot;tên cột tuần sinh&quot;] &amp;lt;37&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/boolean-series.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Nếu ta tính tổng hay trung bình cho Boolean Series, python sẽ treat True=1 và False=0.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;=&amp;gt; Do vậy kết quả của &lt;code&gt;preterm.sum()&lt;/code&gt; là 3742. Đây là số lượng baby sinh non ứng với True.&lt;/p&gt;

&lt;p&gt;Và khi ta tính trung bình của Series, ta sẽ được tỉ lệ của True. Do đó &lt;code&gt;preterm.mean()&lt;/code&gt; cho kết quả ~0.39987. Nghĩ là khoảng 40% số baby có trong dataset này là baby sinh non.&lt;/p&gt;

&lt;h4 id=&quot;filter&quot;&gt;Filter&lt;/h4&gt;

&lt;p&gt;Ta có thể dùng Boolean Series để filter ra các Series giá trị của cột nào đó mà thỏa điều kiện mong muốn.&lt;/p&gt;

&lt;p&gt;Ví dụ để select ra các giá trị cân nặng trong Series birth_weight của các baby sinh non, ta dựa vào Boolean series &lt;code&gt;preterm&lt;/code&gt; tương ứng các record True. Python sẽ đối chiếu cùng index với series chứa cân nặng của baby.&lt;/p&gt;

&lt;p&gt;Sau đó gán kết quả cho biến lưu series trả về chứa các giá trị cân nặng của em bé sinh non. Từ đó ta dễ dàng tính trung bình cân nặng của đối tượng này.
&lt;code&gt;preterm_weight = birth_weigth[preterm]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Ngược lại, để tính toán trung bình cân nặng ta dùng dấu &lt;code&gt;~&lt;/code&gt; trước Boolean series để lấy giá trị ngược lại là False.&lt;/p&gt;

&lt;p&gt;Kết quả:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/boolean-filter.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Nhận xét: Trung bình cân nặng của em bé thường sẽ &amp;gt; hơn em bé sinh non, và điều này hiển nhiên hợp lý.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Nâng cao hơn, ta có thể sử dụng kết hợp &amp;gt;2 boolean series để filter. Khi đó ta sẽ cần dùng đến Logical Operators &lt;code&gt;AND&lt;/code&gt; hoặc &lt;code&gt;OR&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;birth_weight[A &amp;amp; B]	# both true

birth_weight[A | B]	# either or both true
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;resampling&quot;&gt;Resampling&lt;/h3&gt;

&lt;p&gt;Cuối cùng trước khi có thể trả lời câu hỏi cho set dữ liệu, ta cần thực hiện Resampling.&lt;/p&gt;

&lt;p&gt;Nói sơ về &lt;code&gt;Sampling&lt;/code&gt; (lấy mẫu) trước. Sampling là quá trình chọn ra một tập con của một quần thể với mục tiêu đánh giá các tính chất của quần thể đó. Cách thức lấy mẫu phụ thuộc trực tiếp vào mục tiêu đánh giá của chúng ta, do đó sampling nằm gần ranh giới giữa việc quan sát khách quan và việc thực hiện các thực nghiệm mang tính chủ quan.&lt;/p&gt;

&lt;p&gt;Một số khía cạnh chúng ta cần cân nhắc khi lấy mẫu dữ liệu bao gồm:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Mục tiêu.Tính chất của quần thể mà chúng ta muốn khảo sát đánh giá.&lt;/li&gt;
  &lt;li&gt;Quần thể. Phạm vi khảo sát dựa trên lý thuyết.&lt;/li&gt;
  &lt;li&gt;Tiêu chí lựa chọn. Các nguyên tắc cho việc chấp nhận / loại bỏ các quan sát.&lt;/li&gt;
  &lt;li&gt;Kích thước mẫu. Số lượng các quan sát được thu nhận trong mẫu.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;=&amp;gt; &lt;code&gt;Resampling data&lt;/code&gt;có ý nghĩa là cần khảo sát trên mẫu dữ liệu ta thu được nhiều lần để đánh giá độ chắc chắn cho các ước tính.&lt;/p&gt;

&lt;p&gt;Có hai phương pháp resampling thường được sử dụng là bootstrap và k-fold cross-validation:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bootstrap. Các mẫu được lấy ra từ dataset một cách ngẫu nhiên, cho phép một mẫu được xuất hiện nhiều hơn một lần.&lt;/li&gt;
  &lt;li&gt;k-fold Cross-Validation. Dataset được chia thành k nhóm, mỗi nhóm sẽ được sử dụng để đánh giá 1 lần&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-probability-mass-functions-pmf&quot;&gt;5. Probability mass functions (PMF)&lt;/h2&gt;

&lt;h3 id=&quot;pmf-class&quot;&gt;PMF Class&lt;/h3&gt;

&lt;p&gt;Ngoài histogram, ta có thể dùng PMF để quan sát tần số xuất hiện của từng giá trị trong dataset. PMF Class làm việc dựa trên Pandas Series và cung cấp 1 số functions không có trong Pandas.&lt;/p&gt;

&lt;p&gt;Tham số đầu tiên có thể là các loại sequence bất kỳ.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pmf_educ = Pmf(educ, normalize=False)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;*educ ở đây là Series object&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/pmf1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Kết quả trả về 1 PMF object với giá trị ở bên trái và count số lần xuất hiện trong tập dataset ở bên phải.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Để lookup tần suất cho giá trị ở bên trái, ta chỉ cần dùng dấu ngoặc vuông:
&lt;code&gt;pmf_educ[12]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tuy nhiên thông thường khi cần dùng đến PMF thì thường ta muốn biết tỉ lệ xuất hiện của giá trị hơn là đếm&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Lúc này ta chỉ cần set tham số thứ 2 là &lt;code&gt;normalize&lt;/code&gt; = True. Khi đó cột giá trị bên phải trả về tỉ lệ và tổng cột sẽ =1. Nếu muốn biết % ta chỉ cần *100 là được. Cách lookup cho 1 giá trị bất kỳ cũng tương tự trên.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/pmf2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;pmf-bar-chart&quot;&gt;PMF Bar chart&lt;/h3&gt;

&lt;p&gt;PMF có method riêng để hiển thị biểu đồ tần suất. Tùy ta muốn hiển thị tần suất theo tỉ lệ hay count thì ta dùng method lên biến lưu series ở bước trên.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/pmf-bar.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;so-sánh-histogram-và-pmf&quot;&gt;So sánh Histogram và PMF&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;img/hist-pmf.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Tùy trường hợp nhưng trong ví dụ hình trên ta nhận xét:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;PMF show tất cả unique value giúp ta thấy rõ chính xác peak của data ở đâu.&lt;/li&gt;
  &lt;li&gt;Histogram đặt giá trị theo bin nên làm mập mờ các chi tiết quan trọng, như việc ta không thấy peak nằm ở giá trị 12, 14 và 16.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-cumulative-distribution-functions-cdf&quot;&gt;6. Cumulative distribution functions (CDF)&lt;/h2&gt;

&lt;h3 id=&quot;cdf-class&quot;&gt;CDF Class&lt;/h3&gt;

&lt;p&gt;Ngoài PMF, còn các cách khác để thể hiện distribution đó là CDF.&lt;/p&gt;

&lt;p&gt;CDF là cách hay để visualize và so sánh distribution của giá trị.&lt;/p&gt;

&lt;p&gt;CDF cách hoạt động gần giống như PMF, khác nhau ở chỗ:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;PMF cho ra tỉ lệ của 1 giá trị trong series từ 0 đến 1.&lt;/li&gt;
  &lt;li&gt;CDF cho ra tỉ lệ xuất hiện của các giá trị &amp;lt;= giá trị đang tính toán từ 0 đến 1 (percentile).&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;cdf_educ = Cdf(educ, normalize=False)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Xem ví dụ sau:
&lt;img src=&quot;img/cdf.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;vẽ-biểu-đồ-plot-dùng-cdf&quot;&gt;Vẽ biểu đồ plot dùng CDF&lt;/h3&gt;

&lt;p&gt;Ta chỉ cần dùng class &lt;code&gt;Cdf()&lt;/code&gt; và input tham số là sequence của data mà ta muốn biểu thị tần suất. Ở hình dưới là “tuổi”:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/cdf-plot.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Đặc biệt, cdf có thể được sử dụng như 1 function với input là 1 giá trị cụ thể (biến số nguyên).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;q=51
p=cdf(q)
print(p)
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
  &lt;p&gt;Kết quả cho ra 0.66. Nghĩa là có 66% số người có tuổi &amp;lt;=51.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;inverse-cdf&quot;&gt;Inverse CDF&lt;/h3&gt;
&lt;p&gt;CDF là 1 function đảo ngược. Nghĩa là bạn có thể từ giá trị probability (tỉ lệ) mà tra ngược lại giá trị tuổi bằng cách dùng &lt;code&gt;cdf.inverse(giá trị tỉ lệ)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/cdf-inverse.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Từ hình trên có thể nói rằng, tuổi 30 là percentile thứ 25 của distribution này. (do p=0,25)&lt;/p&gt;

&lt;p&gt;Nói sơ thêm về percentile. Khoảng cách từ 25th đến 75th percentile gọi là interquartile range (IQR), nó giúp đo lường sự trải rộng của distribution. Do vậy IQR tương tự như phương sai (variance) hoặc độ lệch chuẩn (standard deviation). Vì IQR được tính toán dựa trên percentiles nên nó sẽ không bị loại đi những giá trị cực hoặc ngoài rìa (cách mà phương sai làm). Do đó IQR “mạnh mẽ” hơn phương sai, nghĩa là nó vẫn làm tốt công việc của nó dù có giá trị lỗi hoặc giá trị cực trong tập data.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Giá trị cực (extreme value) là gì? Là những giá trị khi xuất hiện sẽ ảnh hưởng lớn đến sự thay đổi về xu hướng hội tụ (độ chụm, độ chính xác) kết quả tính toán chung của tập các số như các phép tính trung bình cộng, trung bình nhân,…&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;7-so-sánh-distributions&quot;&gt;7. So sánh Distributions&lt;/h2&gt;

&lt;p&gt;Ta có thể dùng PMF hoặc CDF để plot rồi visualize và phân tích. Tuy nhiên với CDF ta sẽ có cái nhìn rõ ràng, không bị nhiễu và biểu đồ đường (line chart) trông sẽ mượt hơn nhiều.&lt;/p&gt;

&lt;p&gt;Ta ví dụ tập dataset là income của cư dân trước và sau 1995:&lt;/p&gt;

&lt;h5 id=&quot;nếu-dùng-pmf-&quot;&gt;Nếu dùng PMF :&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;img/pmf-compare.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Kết quả chart:
&lt;img src=&quot;img/pmf-compare-chart.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;nếu-dùng-cdf-khuyến-khích&quot;&gt;Nếu dùng CDF (khuyến khích)&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;img/cdf-compare.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Kết quả chart:
&lt;img src=&quot;img/pmf-compare-chart.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Nhận xét data:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Dưới 300000$ thì income hầu như không thay đổi trước và sau 1995. Đường màu cam lệch sang phải ở mốc income 100000-150000$ nghĩa là income sau 1995 của những người có thu nhập cao có xu hướng tăng lên.&lt;/p&gt;
&lt;/blockquote&gt;

</description>
        <pubDate>Fri, 03 Sep 2021 00:00:00 +0700</pubDate>
        <link>http://localhost:5000/data-analysis/</link>
        <guid isPermaLink="true">http://localhost:5000/data-analysis/</guid>
        
        
      </item>
    
      <item>
        <title>Http</title>
        <description>&lt;h3 id=&quot;http-request&quot;&gt;HTTP request&lt;/h3&gt;

&lt;p&gt;HTTP là giao thức (protocol) giúp browser (client) giao tiếp với web server (server).&lt;/p&gt;

&lt;p&gt;Khi bạn truy cập 1 trang web nghĩa là bạn đang gửi 1 HTTP request đến web server. Trong HTTP request sẽ chứa Header và Body.&lt;/p&gt;

&lt;h4 id=&quot;dòng-bắt-đầu-của-http-request-như-1-message-chứa-3-phần-sau&quot;&gt;Dòng bắt đầu của HTTP request (như 1 message) chứa 3 phần sau:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Version của protocol: HTTP/1.1&lt;/li&gt;
  &lt;li&gt;HTTP Method như &lt;code&gt;GET&lt;/code&gt;, &lt;code&gt;POST&lt;/code&gt;, &lt;code&gt;PUT&lt;/code&gt;,&lt;code&gt;HEAD&lt;/code&gt;, &lt;code&gt;OPTION&lt;/code&gt;, &lt;code&gt;DELETE&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Path của request : thông thường là 1 URL và format của nó phụ thuộc vào HTTP method. Ví dụ:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dùng đường dẫn tuyệt đối, phổ biến và thường dùng với GET, POST, HEAD, OPTIONS:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;POST / HTTP/1.1&lt;/li&gt;
  &lt;li&gt;GET /background.png HTTP/1.0 HEAD /test.html?query=alibaba HTTP/1.1&lt;/li&gt;
  &lt;li&gt;OPTIONS /anypage.html HTTP/1.0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dùng đường dẫn hoàn chỉnh khi cần kết nối với proxy thông qua method GET:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GET https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages HTTP/1.1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Chỉ dùng authority form khi cần setup HTTP tunnel (domain name : port) bằng method CONNECT:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CONNECT developer.mozilla.org:80 HTTP/1.1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dùng dấu &lt;code&gt;'*'&lt;/code&gt; khi muốn đường dẫn đại diện cho toàn bộ máy chủ thông qua method OPTIONS:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;OPTIONS * HTTP/1.1&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;header-chứa-các-thông-tin-của-request-và-hầu-hết-ở-dưới-dạng-keyvalue&quot;&gt;Header chứa các thông tin của request và hầu hết ở dưới dạng key:value.&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;img/HTTP-header.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Header của request được chia thành vài group chính:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;General header: apply cho toàn bộ message&lt;/li&gt;
  &lt;li&gt;Response header: chỉ định thêm cho request bằng cách sửa đổi 1 số thông số&lt;/li&gt;
  &lt;li&gt;Representation headers: như Content-Type để mô tả format của data gửi lên server và cho biết nếu data đó có apply encoding nào không (chỉ có phần này khi request có Body)&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;header-key-có-thể-được-set-tùy-chỉnh-value&quot;&gt;Header key có thể được set tùy chỉnh value&lt;/h5&gt;

&lt;p&gt;Trong POST method, bạn tùy chỉnh theo mẫu sau:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Use case: Set the output type as JSON and json.dumps your output.
# Set_default_headers in a parent class called RESTRequestHandler. If you want just one request that is returning JSON you can set the headers in the post call.

class strest(tornado.web.RequestHandler):
    def set_default_headers(self):
        self.set_header(&quot;Content-Type&quot;, 'application/json')

    def post(self):
        value = self.get_argument('key')
        cbtp = cbt.main(value)
        r = json.dumps({'cbtp': cbtp})
        self.write(r)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Tham khảo thêm các key info trong header tại: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers&lt;/p&gt;

&lt;h4 id=&quot;body&quot;&gt;Body&lt;/h4&gt;
&lt;p&gt;Không phải method nào cũng cần Body, hầu như GET, HEAD, DELETE, OPTIONS ít cần. Thông thường khi cần gửi request update thông tin gì đó lên server thì người ta dùng method POST request (chứa dữ liệu HTML form).&lt;/p&gt;

&lt;p&gt;Body chia thành 2 loại :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Single-resource body: chứa 1 loại file duy nhất, được định nghĩa bởi Content-Type và Content-Length (trong header).&lt;/li&gt;
  &lt;li&gt;Multiple-resource body : chứa multipart data, mỗi part chứa một số thông tin khác nhau. Các part được phân tác bởi dấu &lt;code&gt;--&lt;/code&gt; trong header ở phần Content-Type. Loại này thường được sử dụng với HTML form.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;Content-Type: multipart/form-data; boundary=aBoundaryString
(other headers associated with the multipart document as a whole)

--aBoundaryString
Content-Disposition: form-data; name=&quot;myFile&quot;; filename=&quot;img.jpg&quot;
Content-Type: image/jpeg

(data)
--aBoundaryString
Content-Disposition: form-data; name=&quot;myField&quot;

(data)
--aBoundaryString
(more subparts)
--aBoundaryString--
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;http-method&quot;&gt;HTTP Method:&lt;/h3&gt;

&lt;h4 id=&quot;get&quot;&gt;GET&lt;/h4&gt;
&lt;p&gt;Dữ liệu request sẽ hiển thị trên URL nên không bảo mật. Phù hợp khi cần download về dữ liệu gì đó vì nó truy xuất nhanh khi dữ liệu không hoặc ít bị thay đổi.&lt;/p&gt;

&lt;p&gt;Dữ liệu của phương thức này gửi đi thì hiện trên thanh địa chỉ (URL) của trình duyệt.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/test/demo_form.php?user=itplus&amp;amp;password=admin&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Đặc điểm:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;HTTP GET có thể được cache bởi trình duyệt&lt;/li&gt;
  &lt;li&gt;HTTP GET có thể duy trì bởi lịch sử đó cũng là lý do mà người dùng có thê bookmark được.&lt;/li&gt;
  &lt;li&gt;HTTP GET không được sử dụng nếu trong form có các dữ liệu nhạy cảm như là password, tài khoản ngân hàng&lt;/li&gt;
  &lt;li&gt;HTTP GET bị giới hạn số trường độ dài data gửi đi&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;post&quot;&gt;POST&lt;/h4&gt;
&lt;p&gt;Dữ liệu gửi đi (khi request) sẽ không bị hiển thị trên thanh URL vì nó đã được encode (mã hóa) nên độ bảo mật cao.&lt;/p&gt;

&lt;p&gt;Đặc điểm:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;HTTP POST không cache bởi trình duyệt&lt;/li&gt;
  &lt;li&gt;HTTP POST không thể duy trì bởi lịch sử đó cũng là lý do mà người dùng không thê bookmark HTTP POST được.&lt;/li&gt;
  &lt;li&gt;HTTP POST không giới hạn dữ liệu gửi đi&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;phân-biệt-post-và-get&quot;&gt;Phân biệt POST và GET&lt;/h4&gt;

&lt;p&gt;Điểm chung: là các HTTP method dùng để trao đổi dữ liệu giữa client và server.&lt;/p&gt;

&lt;p&gt;Điểm khác nhau:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;POST: Bảo mật hơn GET vì dữ liệu được gửi&lt;/li&gt;
  &lt;li&gt;GET: Dữ liệu được gửi tường minh, chúng ta có thể nhìn thấy trên URL, đây là lý do khiến nó không bảo mật so với POST.&lt;/li&gt;
  &lt;li&gt;GET thực thi nhanh hơn POST vì những dữ liệu gửi đi luôn được webbrowser cached lại.&lt;/li&gt;
  &lt;li&gt;Khi dùng phương thức POST thì server luôn thực thi và trả về kết quả cho client, còn phương thức GET ứng với cùng một yêu cầu đó webbrowser sẽ xem trong cached có kết quả tương ứng với yêu cầu đó không và trả về ngay không cần phải thực thi các yêu cầu đó ở phía server.&lt;/li&gt;
  &lt;li&gt;Đối với những dữ liệu luôn được thay đổi thì chúng ta nên sử dụng phương thức POST, còn dữ liệu ít thay đổi chúng ta dùng phương thức GET để truy xuất và xử lý nhanh hơn.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;head&quot;&gt;HEAD&lt;/h4&gt;
&lt;p&gt;Trả về response là header của request.&lt;/p&gt;

&lt;h3 id=&quot;http-response&quot;&gt;HTTP response&lt;/h3&gt;
&lt;p&gt;Dòng đầu phần response chứa 3 thông tin:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Protocol version&lt;/li&gt;
  &lt;li&gt;Status code: mã trạng thái trả về để biết request thành công hay thất bại&lt;/li&gt;
  &lt;li&gt;Status text: text để giải thích cho code&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Header của response được chia thành vài group chính:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;General header: apply cho toàn bộ message&lt;/li&gt;
  &lt;li&gt;Response header: chỉ định thêm cho request bằng cách sửa đổi 1 số thông số.&lt;/li&gt;
  &lt;li&gt;Representation headers: như Content-Type để mô tả format của data trong response message và cho biết nếu data có apply encoding nào không (chỉ có phần này khi request có Body).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;img/HTTP-response.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;body-1&quot;&gt;Body&lt;/h4&gt;
&lt;p&gt;Không phải response nào cũng có body khi mà response đã đáp ứng đủ request mà không cần payload gì thêm. VÍ dụ như các status code như 201 Created hoặc 204 No Content.&lt;/p&gt;

&lt;p&gt;Body response có thể chia thành 3 loại :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Single-resource body: chứa 1 loại file duy nhất, được định nghĩa bởi Content-Type và Content-Length (trong header).&lt;/li&gt;
  &lt;li&gt;Single-resource body: chứa 1 loại file duy nhất, không biết độ dài, được mã hóa bằng các khối với key Transfer-Encoding : chunked.&lt;/li&gt;
  &lt;li&gt;Multiple-resource body : chứa multipart section, mỗi section chứa một số thông tin khác nhau. Loại này ít gặp.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;Ref: https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages
https://developer.ibm.com/articles/what-is-curl-command/&lt;/p&gt;
</description>
        <pubDate>Thu, 02 Sep 2021 00:00:00 +0700</pubDate>
        <link>http://localhost:5000/http/</link>
        <guid isPermaLink="true">http://localhost:5000/http/</guid>
        
        
      </item>
    
      <item>
        <title>Setup Jekyll themes</title>
        <description>&lt;h2 id=&quot;fork-jekyll-theme--play&quot;&gt;Fork Jekyll theme &amp;amp; Play&lt;/h2&gt;

&lt;p&gt;Đây là theme blog mình đang sử dụng: https://github.com/tuyen-nnt/jekyll-theme-memoirs&lt;/p&gt;

&lt;p&gt;Các bước build Jekyll cho blog này: https://bootstrapstarter.com/jekyll-theme-memoirs/
(Tìm hiểu thêm tại: https://jekyllrb.com/docs/)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;B1: git clone https://github.com/wowthemesnet/jekyll-theme-memoirs.git&lt;/li&gt;
  &lt;li&gt;B2: Tải Ruby https://www.ruby-lang.org/en/documentation/installation/&lt;/li&gt;
  &lt;li&gt;B3: cd vào thư mục theme rồi &lt;code&gt;gem install bundler&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;B4: &lt;code&gt;bundle install&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Kết quả build thành công:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/bundle-install.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;B5: Sửa lại &lt;code&gt;_config.yml&lt;/code&gt; theo blog của mình&lt;/li&gt;
  &lt;li&gt;B6: &lt;code&gt;bundle exec jekyll serve --watch&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;B7: Xem web blog tại http://127.0.0.1:4000/jekyll-theme-memoirs (nếu folder vẫn giữ tên cũ)&lt;/li&gt;
  &lt;li&gt;B8: Thêm blogs định dạng &lt;code&gt;.md&lt;/code&gt; vào folder &lt;code&gt;_posts&lt;/code&gt;. Trước mỗi bài viết sẽ có ô YAML là định dạng chung, bạn chỉ cần điền vào thông tin của mình là được (nhưng vẫn giữ form nhé). Chi tiết xem link các bước thực hiện.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tìm hiểu về Bundler install: https://bundler.io/&lt;/p&gt;

&lt;p&gt;Tìm hiểu về Gemfile: https://bundler.io/gemfile.html&lt;/p&gt;

</description>
        <pubDate>Tue, 10 Aug 2021 00:00:00 +0700</pubDate>
        <link>http://localhost:5000/Jekyll-install/</link>
        <guid isPermaLink="true">http://localhost:5000/Jekyll-install/</guid>
        
        
        <category>Git</category>
        
        <category>Blog</category>
        
        <category>Web</category>
        
      </item>
    
      <item>
        <title>Python - Part 2</title>
        <description>&lt;h4 id=&quot;1-dictionaries&quot;&gt;1. Dictionaries&lt;/h4&gt;
&lt;p&gt;Là tập hợp các cặp &lt;code&gt;key:value&lt;/code&gt; khi cần kết nối dữ liệu với nhau như 1 table để tra cứu nhanh và có thể chỉ ra unique keys khi tra cứu, thay vì nối 2 list lại để lấy index rồi tra cứu value.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;So sánh giữa list và dict:
&lt;img src=&quot;img/list-vs-dict.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cú pháp tạo dict như sau:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;my_dict = {
	key:value,
	key:value
}&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Access dict như sau:
&lt;code&gt;my_dict['key']&lt;/code&gt; =&amp;gt; cho ra value của key đó.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Thêm key:value vào dict:
&lt;code&gt;world[&quot;sealand&quot;] = 0.25&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Check xem dict đã được thêm key ở trên vào chưa: 
&lt;code&gt;sealand in world&lt;/code&gt; =&amp;gt; trả về True/False.
Với ‘seadland’ là key và word là tên dict.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cập nhật lại giá trị cho key &lt;code&gt;sealand&lt;/code&gt;:
&lt;code&gt;world['sealand'] = 0.28&lt;/code&gt;
Vì key trong dict là unique nên Python hiểu là bạn muốn thay đổi giá trị chứ không phải tạo mới cặp key:value.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Xóa cặp key:value:
&lt;code&gt;del(world['sealand'])&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dict trong dict:
Cũng như list có thể chứa list trong list. Xem ví dụ:&lt;/p&gt;
    &lt;pre&gt;&lt;code&gt;# Dictionary of dictionaries
europe = { 'spain': { 'capital':'madrid', 'population':46.77 },
         'france': { 'capital':'paris', 'population':66.03 },
         'germany': { 'capital':'berlin', 'population':80.62 },
         'norway': { 'capital':'oslo', 'population':5.084 } }
&lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt;Để access giá trị của dict, ta sẽ dùng dấu [] như trong array:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;europe['spain']['population']&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;=&amp;gt; Vậy để add thêm cặp key:dict vào trong dict trên thì làm thế nào?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Create sub-dictionary data
data = {
    'capital':'rome',
    'population':59.83
}

# Add data to europe under key 'italy'
europe['italy'] = data
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ta chỉ cần tách ra tạo dict phụ trước và gán nó vào biến lưu object value. Sau đó ta thêm cặp key:value vào dict như bình thường.&lt;/p&gt;

&lt;p&gt;Lưu ý:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Keys không được trùng nhau trong 1 dict, vì nếu trùng, nó sẽ chỉ lấy giá trị cuối cùng.&lt;/li&gt;
  &lt;li&gt;Keys phải là immutable object (không đổi), còn list thì mutable nên list cũng không được là key trong dict.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2-pandas&quot;&gt;2. Pandas&lt;/h4&gt;

&lt;h5 id=&quot;tabular-dataset-trong-python&quot;&gt;Tabular dataset trong Python&lt;/h5&gt;
&lt;p&gt;row = observations&lt;/p&gt;

&lt;p&gt;column = variable&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Để làm việc với dạng data này thì cần cấu trúc dạng chữ nhật.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;=&amp;gt; 2D Numpy array&lt;/p&gt;

&lt;p&gt;=&amp;gt; Nhưng với các dữ liệu có nhiều thông tin với nhiều datatype khác nhau như str, float,… thì Numpy chưa hiệu quả.&lt;/p&gt;

&lt;p&gt;Vậy nên pandas package chính là solution và quen thuộc trong Data science.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Nó được build dựa trên Numpy.&lt;/li&gt;
  &lt;li&gt;Là tool ở cấp độ cao trong thao tác với dữ liệu.&lt;/li&gt;
  &lt;li&gt;Pandas lưu dữ liệu bảng trong object gọi là Dataframe.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cách tạo dataframe từ dictionary:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import pandas as pd
brics = pd.DataFrame(dict)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;img/create-df.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Để tạo index cho observations trong df, ta dùng attribute &lt;code&gt;index&lt;/code&gt; và gán 1 list với thứ tự chính xác các index mong muốn:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;brics.index = [...,...]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;img/index-df.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;csv-file&quot;&gt;CSV file&lt;/h5&gt;
&lt;p&gt;Nhưng thực tế trong Data science, ta phải đối mặt với lượng data khổng lồ tùy trường hợp cụ thể, nên thông thường ta không tự tạo dataframe. Giả sử các data đến từ file có &lt;code&gt;.csv&lt;/code&gt; viết tắt của comma separated values.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Để import vào môi trường Python ta dùng cú pháp:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;brics = pd.read_csv(&quot;path/to/brics.csv&quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
  &lt;li&gt;Tuy nhiên đối với file có index, khi import vào thì cột index đầu tiên sẽ bị ngầm hiểu là cột đầu của dữ liệu chính. Để tránh điều này, ta phải thêm argument &lt;code&gt;index_col=0&lt;/code&gt;, kết quả:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;img/csv-import.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Để thay đổi index tự động từ 0-n bằng label được định nghĩa trong 1 list tạo riêng tự chọn, ta dùng cú pháp:
```
    &lt;h1 id=&quot;definition-of-row_labels&quot;&gt;Definition of row_labels&lt;/h1&gt;
    &lt;p&gt;row_labels = [‘US’, ‘AUS’, ‘JPN’, ‘IN’, ‘RU’, ‘MOR’, ‘EG’]&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;specify-row-labels-of-cars&quot;&gt;Specify row labels of cars&lt;/h1&gt;
&lt;p&gt;cars.index = row_labels&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
##### Cách để access Dataframe
Ta input vào label hoặc index của column hoặc row. Ví dụ cụ thể ta có df là cars, xem cú pháp dưới đây: 

* Access COLUMN (cột):
	* Dùng [] : 
	- Nếu muốn output là Series object: ``cars['country', ... ]``
	- Nếu muốn output là Dataframe, dùng double ngoặc vuông:
``cars[['country', ... ]]``
&amp;gt; Nhìn ở góc khác, ta đang input vào ngoặc vuông 1 list chứa column labels.

	* Dùng ``loc`` (chọn 1 phần data dựa trên label-based) hoặc ``iloc`` (chọn data dựa trên integer position-based)
	- cars.loc['country', ...] hoặc cars.loc[['country', ...]] 
	- car.iloc[0, ..., ...] hoặc car.iloc[[0, ..., ...]]
	
* Access ROW (quan sát)	
	* Chỉ có cách là dùng [] nhưng input vào số:
	- Nếu muốn lấy row từ index 1 đến 3:
``cars[1:4]`` 
	* Dùng loc hoặc iloc và input vào index của row thay vì tên cột như truy cập vào column.

* Access ROWs &amp;amp; COLUMNs bất kì:
	* Sử dụng loc và iloc tiện lợi:
	- Ta chỉ cần đặt vào label của row và column trong loc hoặc iloc theo thứ tự ``row, column``. 
	- Nếu chọn nhiều hơn 1 label trong row hoặc column, ta biến argument row hoặc column thành list.

Xem	 hình ví dụ:
	
![](img/loc-iloc.png)

	
&amp;gt; Nhận xét: 

- Dấu ngoặc vuông``[]`` có giới hạn chức năng và lý tưởng nhất là sử dụng trong 2D Numpy array để access value dễ dàng nhất.	
- Nếu muốn dấu``[]``có thể mở rộng khả năng access value trong pandas như  dấu``[]``trong 2D Numpy array, thì ta cần sử dụng ``loc`` và ``iloc``.

![](img/iloc-loc.png)
	
	
##### Filter dataframe

* Bước 1: Access cột trả về series object.

* Bước 2: Xác định điều kiện filter và trả về Boolean Series. Nếu &amp;gt; 2 điều kiện thì phải sử dụng Numpy variants của toán tử and, or, not.

* Bước 3: Dùng Boolean Series là kết quả của bước 1 làm input trong dấu ngoặc vuông của Dataframe. Kết quả trả về các record thỏa điều kiện.

&amp;gt; You'll want to build up a boolean Series, that you can then use to subset the cars DataFrame to select certain observations. If you want to do this in a one-liner, that's perfectly fine!


#### 3. LOOP

##### WHILE


##### FOR 

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;for var in seq :
	expression&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
Trong đó ``var`` là biến bất kỳ có thể đặt tên sao cũng được. Python dùng nó để quét lần lượt cái phần tử trong ``seq``.


FOR còn dùng để lặp từng char trong string.
![](img/string-loop.png)

* enumerate() : cung cấp 2 giá trị cho mỗi lần lặp gồm ``index`` và ``value (giá trị)``.

![](img/enumerate-for.png)



Mỗi data structure sẽ có cách loop các nhau và cách định nghĩa sequence khác nhau (seq). Cụ thể các bạn xem dưới đây nhé:

##### Loop với List của Lists 
* Nếu list mà bạn cần lặp là list của list, thì dùng cách như sau:

&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;house-list-of-lists&quot;&gt;house list of lists&lt;/h1&gt;
&lt;p&gt;house = [[“hallway”, 11.25], 
         [“kitchen”, 18.0], 
         [“living room”, 20.0], 
         [“bedroom”, 10.75], 
         [“bathroom”, 9.50]]&lt;/p&gt;

&lt;h1 id=&quot;build-a-for-loop-from-scratch&quot;&gt;Build a for loop from scratch&lt;/h1&gt;
&lt;h1 id=&quot;x-quét-từng-list-trong-list-dùng--để-truy-cập-phần-tử-của-sub-list&quot;&gt;x quét từng list trong list, dùng [] để truy cập phần tử của sub-list&lt;/h1&gt;

&lt;p&gt;for x in house :
    print(“the “ + x[0] + “ is “ + str(x[1]) + “ sqm”)
```&lt;/p&gt;

&lt;h5 id=&quot;loop-với-dictionary&quot;&gt;Loop với Dictionary&lt;/h5&gt;
&lt;p&gt;Sử dụng method &lt;code&gt;items()&lt;/code&gt; :&lt;/p&gt;

&lt;p&gt;&lt;code&gt;for key, val in my_dict.items() :&lt;/code&gt;&lt;/p&gt;

&lt;h5 id=&quot;loop-với-numpy-array&quot;&gt;Loop với Numpy array&lt;/h5&gt;
&lt;p&gt;Sử dụng function &lt;code&gt;np.nditer(my_array)&lt;/code&gt; đặc biệt là với 2D array.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;for val in np.nditer(my_array) :&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Với 1D array ta có thể sử dụng loop thông thường, nhưng với 2D thì nó sẽ in ra 2D array thay vì ra các giá trị cần lấy trong loop.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dùng &lt;code&gt;nditer&lt;/code&gt; sẽ giúp in ra từng giá trị từ trái sang phải từ trên xuống dưới của 2D array.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;pandas-dataframe&quot;&gt;Pandas DataFrame&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;iterrows()&lt;/code&gt; : Trong mỗi lần lặp, method này sẽ generate ra 2 giá trị:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Label của row (nếu ko có thì là index tự động)&lt;/li&gt;
  &lt;li&gt;Data của row (là Pandas Series có index/label là tên cột - còn gọi là fieldname)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;img/iterrows.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Để loop in ra giá trị của cột mong muốn cho mỗi lần lặp, ta chỉ cần:&lt;/p&gt;

&lt;p&gt;print(row[“tên cột”])&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Thêm cột vào Dataframe bằng loop:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ví dụ ta muốn thêm cột tính độ dài của cột “country”:
&lt;code&gt;brics.loc[lab, &quot;tên cột mới&quot;] = len(row[&quot;country&quot;])&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/new-col.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Nhận xét: Cách này tốt trong trường hợp ít record. Vì ta đang tạo ra Series object cho mỗi vòng lặp và nó sẽ không hiệu quả với các dataset khổng lồ, thậm chí gây ra vấn đề khi xử lý dữ liệu.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Vậy nên, cách tốt nhất là ta sử dụng function &lt;code&gt;apply(tên function)&lt;/code&gt; cho mỗi cột mà ta muốn tính toán rồi gán vào cột mới trong dataframe:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;brics[&quot;cột mới&quot;] = brics[&quot;country&quot;].apply(len)&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Cách hoạt động: Function &lt;code&gt;apply()&lt;/code&gt; sẽ gọi function &lt;code&gt;len()&lt;/code&gt; mà mỗi giá trị của cột country sẽ là input để tính độ dài từng country. Kết quả trả về là 1 array mà chúng ta có thể dễ dàng lưu thành cột mới trong Dataframe.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Mon, 02 Aug 2021 00:00:00 +0700</pubDate>
        <link>http://localhost:5000/python-intermediate/</link>
        <guid isPermaLink="true">http://localhost:5000/python-intermediate/</guid>
        
        
        <category>Data</category>
        
        <category>Programing</category>
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>Import Data - Part 2</title>
        <description>&lt;h4 id=&quot;1-import--load--tạo-httpget-request&quot;&gt;1. Import + Load + Tạo HTTP/GET REQUEST&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Lưu file mềm xuống local:
&lt;code&gt;urlretrieve(url, 'filename.csv')&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Trước tiên phải &lt;code&gt;from urllib.request import urlretrieve&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Mở và đọc file mềm trên web:
&lt;code&gt;
df = pd.read_csv(url, sep=';')
&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Show các dòng đầu tiên của df:
&lt;code&gt;
print(df.head())
&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;URL (Uniform/Universal Resource Locator)
phần lớn là các địa chỉ web, ngoài ra còn là FTP (file transfer protocol)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;URL gồm 2 phần:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Protocol Identifier : http hoặc https&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tên resource: datacamp.com
=&amp;gt; tạo thành 1 địa chỉ web&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;HTTP (HyperText Transfer Protocol)
Là protocol ứng dụng cho các hệ thống thông tin phân tán, cộng tác và siêu phương tiện, nền tảng giao tiếp dữ liệu cho WWW.
HTTPS - có độ an toàn bảo mật cao hơn HTTP&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Mỗi khi truy cập vào 1 trang web nghĩa là bạn đang gửi 1 HTTP request cho 1 server. Request này được gọi là GET request, đây là loại request phổ biến nhất.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;urlretrieve : gửi GET request và lưu dữ liệu xuống local máy&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;HTML (HyperText Markup Language)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2-các-cách-gửi-get-request&quot;&gt;2. Các cách gửi GET request:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Cách 1&lt;/strong&gt;: sử dụng &lt;code&gt;urllib.request&lt;/code&gt;
=&amp;gt; &lt;code&gt;from urllib.request import urlopen, Request&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Một số functions của package &lt;code&gt;urllib.request&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;request = Request(url)&lt;/code&gt; : đóng gói GET request&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;response = urlopen(request)&lt;/code&gt; : 
gửi request và catch phản hồi =&amp;gt; trả về HTTP response object có tích hợp method read() và close()&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;html = response.read()&lt;/code&gt; : trả về HTML định dạng string&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code&gt;response.close()&lt;/code&gt;: dùng xong nhớ đóng lại&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cách 2&lt;/strong&gt;: rất phổ biến, sử dụng package &lt;code&gt;requests&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cho phép gửi HTTP request có tổ chức mà ko cần làm thủ công&lt;/p&gt;

&lt;p&gt;requests.get(url) : sau khi import package requests, hàm request.get() sẽ đóng gói request thông qua url, gửi request đi và nhận lại phản hồi và lưu vào biến r.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Ở đây hàm &lt;code&gt;request.get()&lt;/code&gt; sẽ làm nhiệm vụ của &lt;code&gt;Request(url)&lt;/code&gt; và &lt;code&gt;urlopen(request đã đóng gói)&lt;/code&gt;của cách 1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;r.text : r là biến lưu response của hàm trên, sử dụng method .text cho response để chuyển HTML của url sang dạng string.&lt;/p&gt;

&lt;h4 id=&quot;3-scraping-web-trong-python&quot;&gt;3. Scraping web trong Python&lt;/h4&gt;

&lt;p&gt;HTML là sự kết hợp của data có cấu trúc và không cấu trúc.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hàm &lt;code&gt;BeautifulSoup()&lt;/code&gt; có tác dụng parse và trích xuất data từ HTML, và làm cho các tag được biểu diễn đẹp hơn.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cách sử dụng: 
&lt;code&gt;from bs4 import BeautifulSoup&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Sau khi gửi nhận phản hồi của GET request, ta được file html như trên.&lt;/p&gt;

&lt;p&gt;Sau đó, ta dùng hàm &lt;code&gt;BeautifulSoup&lt;/code&gt; để extract các data có cấu trúc của file html, lưu kết quả là một object vào một biến mới. Kết quả của hàm &lt;code&gt;BeautifulSoup&lt;/code&gt;có tích hợp hàm &lt;code&gt;.prettify()&lt;/code&gt; để làm đẹp kết quả.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;soup = BeautifulSoup(html_doc)
print(soup.prettify())&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Các hàm khác có thể dùng sau khi parse và nhận kết quả từ BeautifulSoup:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;code&gt;soup.title()&lt;/code&gt; : trích title của file html&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;soup.get_text()&lt;/code&gt;: trích tất cả text của file html&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;soup.find_all()&lt;/code&gt; : tìm tất cả các data theo điều kiện hoặc tag nào đó.
  Ví dụ:
        &lt;pre&gt;&lt;code&gt;  for link in soup.find_all('a'):
  print(link.get('href')
&lt;/code&gt;&lt;/pre&gt;
        &lt;p&gt;hoặc&lt;/p&gt;
        &lt;pre&gt;&lt;code&gt;  for link in a_tags:
  print(link.get('href'))
&lt;/code&gt;&lt;/pre&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;=&amp;gt; Ở đây, ta sử dụng vòng lặp for kết hợp hàm &lt;code&gt;.find_all()&lt;/code&gt; extract data nằm trong tag &lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt; của file html và in ra từng link của mỗi dòng tìm được, ta cũng có thể lưu &lt;code&gt;soup.find_all()&lt;/code&gt; vào một biến nào đó.
Hàm &lt;code&gt;link.get('href')&lt;/code&gt; dùng để extract giá trị link của attribute href trong tag &lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&quot;4-load-và-khám-phá-file-json&quot;&gt;4. Load và khám phá file JSON&lt;/h4&gt;
&lt;h6 id=&quot;file-json-nằm-ở-local&quot;&gt;FIle JSON nằm ở local&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Bước 1: Tạo connection với file JSON trong local và load file
    &lt;pre&gt;&lt;code&gt;with open(&quot;tên file.json&quot;) as json_file :
  json_data = json.load(json_file)
&lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt;Ở đây json_data là 1 object dictionary, ta check bằng &lt;code&gt;type(json_data)&lt;/code&gt; ra kết quả &lt;code&gt;dict&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Bước 2: Sử dụng vòng lặp &lt;code&gt;for&lt;/code&gt; để in cặp key-value ra
    &lt;pre&gt;&lt;code&gt;for k in json_data.keys():
  print(k + ': ', json_data[k])
&lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt;Từ object dictionary trên, ta dùng àm &lt;code&gt;.keys&lt;/code&gt; để truy cập vào keys của file và dùng cú pháp &lt;code&gt;dictionary[key]&lt;/code&gt; để truy cập vào value.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;5-apis-và-tương-tác-cơ-bản&quot;&gt;5. APIs và tương tác cơ bản&lt;/h4&gt;

&lt;h5 id=&quot;api-là-gì&quot;&gt;API là gì?&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;Là một bộ protocols và routines để xây dựng và tương tác với phần mềm&lt;/li&gt;
  &lt;li&gt;Một tập hợp code cho phép 02 chương trình phần mềm giao tiếp với nhau
Ví dụ nếu muốn stream data của Twitter thì ta cùng API của Twitter.&lt;/li&gt;
  &lt;li&gt;Thông thường data thường được lấy về từ APIs ở định dạng JSON.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;url-có-gì-và-làm-thể-nào-để-nó-biết-pull-data-từ-api-về&quot;&gt;URL có gì và làm thể nào để nó biết pull data từ API về?&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;url = 'http://www.omdbapi.com/?t=hackers'&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;http - dấu hiệu là ta đang tạo 1 HTTP request&lt;/li&gt;
  &lt;li&gt;www.omdbapi.com - nghĩa là ta đang query OMDB API&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;?t=hackers&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;Đây gọi là Query String&lt;/li&gt;
      &lt;li&gt;Không có quy ước và không buộc có trong đường dẫn&lt;/li&gt;
      &lt;li&gt;Sau dấu &lt;code&gt;?&lt;/code&gt; là phần query. Theo document trên trang chủ OMDB API thì có nghĩ là ta đang muốn trả về data của bộ phim có title (t) ‘Hackers’. Cụ thể xem phần Usage + Parameters.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;# Import package
import requests

# Assign URL to variable: url
url = 'https://en.wikipedia.org/w/api.php?action=query&amp;amp;prop=extracts&amp;amp;format=json&amp;amp;exintro=&amp;amp;titles=pizza'

# Package the request, send the request and catch the response: r
r = requests.get(url)

# Decode the JSON data into a dictionary: json_data
json_data = r.json()

print(json_data)

# Print the Wikipedia page extract
pizza_extract = json_data['query']['pages']['24768']['extract']
print(pizza_extract)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ở 2 dòng code cuối, để biết tại sao code như thế, ta truy cập url trên browser, nó sẽ hiện ra các tab. Ta muốn extract data từ api của url thì ta mở từ tab &lt;code&gt;query &amp;gt; pages &amp;gt; 24768 &amp;gt; extract&lt;/code&gt; thì sẽ nhận được data từ api đó.&lt;/p&gt;

&lt;h5 id=&quot;load-và-khám-phá-twitter-data&quot;&gt;Load và khám phá Twitter data&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# Import package
import json

# String of path to file: tweets_data_path
tweets_data_path = 'tweets.txt'

# Initialize empty list to store tweets: tweets_data
tweets_data = []

# Open connection to file
tweets_file = open(tweets_data_path, &quot;r&quot;)

# Read in tweets and store in list: tweets_data
for line in tweets_file:
    tweet = json.loads(line)
    tweets_data.append(tweet)

# Close connection to file
tweets_file.close()

# Print the keys of the first tweet dict
print(tweets_data[0].keys())
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;Đầu tiên ta gán đường dẫn tên file chứa Twitter data ở local máy vào 1 biến.&lt;/li&gt;
  &lt;li&gt;Tiếp theo ta tạo 1 mảng rỗng để chứa mỗi dòng tweet là 1 phần tử trong mảng.&lt;/li&gt;
  &lt;li&gt;Sau đó ta mở connection đến file local đó thông qua dường dẫn &lt;code&gt;tweets_data_path&lt;/code&gt; và lưu vào &lt;code&gt;tweets_file&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Tiếp theo ta dùng vòng lặp for để đọc từng dòng của &lt;code&gt;tweets_file&lt;/code&gt;:
    &lt;ul&gt;
      &lt;li&gt;Dùng hàm &lt;code&gt;json.load(line)&lt;/code&gt; để load từng dòng lưu vào biến &lt;code&gt;tweet&lt;/code&gt;, &lt;em&gt;để dùng hàm trên phải import &lt;code&gt;json&lt;/code&gt; package&lt;/em&gt;
        &lt;blockquote&gt;
          &lt;p&gt;Note: mỗi lần load &lt;code&gt;line&lt;/code&gt; để lưu vào &lt;code&gt;tweet&lt;/code&gt; là một dictionary.&lt;/p&gt;
        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;Sử dụng biến mảng &lt;code&gt;tweets_data&lt;/code&gt; kết hợp hàm &lt;code&gt;append(tweet)&lt;/code&gt; để add thêm phần tử dictionary mới (hay còn gọi là tweet) vào mảng.&lt;/li&gt;
      &lt;li&gt;In ra tất cả các &lt;code&gt;keys&lt;/code&gt; của phần tử đầu tiên (tweet hay dict) của mảng.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;đưa-mảng-vào-dataframe-sử-dụng-package-pandas-để-phân-tích&quot;&gt;Đưa mảng vào Dataframe sử dụng package pandas để phân tích&lt;/h5&gt;

&lt;pre&gt;&lt;code&gt;# Import package
import pandas as pd

# Build DataFrame of tweet texts and languages
df = pd.DataFrame(tweets_data, columns=['text','lang'])
 
# Print head of DataFrame

print(df.head())
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
  &lt;li&gt;Hàm &lt;code&gt;pd.Dataframe()&lt;/code&gt; cần 2 tham số là data và column để xây dựng df
    &lt;ul&gt;
      &lt;li&gt;Tham số đầu có thể là mảng, dict hoặc dataframe&lt;/li&gt;
      &lt;li&gt;Tham số thứ 2 là column label, nếu không có label thì dùng RangeIndex(0,1,2,…n). Nếu có label trong data như ví dụ trên, ta chỉ cần &lt;code&gt;columns=['text','lang']&lt;/code&gt; để chọn label cho column muốn rút giá trị. Ở ví dụ trên ta sẽ tạo 2 cột &lt;code&gt;text&lt;/code&gt; và &lt;code&gt;lang&lt;/code&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;streaming&quot;&gt;Streaming&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# Initialize Stream listener
l = MyStreamListener()

# Create your Stream object with authentication
stream = tweepy.Stream(auth, l)

# Filter Twitter Streams to capture data by the keywords:
stream.filter(track=['clinton', 'trump', 'sanders', 'cruz'])
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Class &lt;code&gt;MyStreamListener()&lt;/code&gt; được khai báo sẵn tại đây: https://gist.github.com/hugobowne/18f1c0c0709ed1a52dc5bcd462ac69f4&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ta tạo object &lt;code&gt;stream&lt;/code&gt;bằng cách đưa vào hàm &lt;code&gt;tweepy.Stream()&lt;/code&gt; athentication handler &lt;code&gt;auth&lt;/code&gt; và object &lt;code&gt;l&lt;/code&gt; - stream listener trên.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Object &lt;code&gt;stream&lt;/code&gt; có tích hợp hàm &lt;code&gt;.filter()&lt;/code&gt;, trong hàm này có attribute &lt;code&gt;track=[]&lt;/code&gt; là list chứa các keyword mà ban muốn filter.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;phân-tích-data-cơ-bản&quot;&gt;Phân tích data cơ bản&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;import re

def word_in_text(word, text):
    word = word.lower()
    text = text.lower()
    match = re.search(word, text)

    if match:
        return True
    return False
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;Ở trên ta có hàm &lt;code&gt;word_in_text()&lt;/code&gt; để đếm số lượng tweet chứa keyword. Nhưng ở đây chúng ta chưa đếm, mà chỉ đưa kết quả nếu True sẽ +1 vào biến đếm ở bước tiếp theo.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;# Initialize list to store tweet counts
[clinton, trump, sanders, cruz] = [0, 0, 0, 0]

# Iterate through df, counting the number of tweets in which
# each candidate is mentioned
for index, row in df.iterrows():
    clinton += word_in_text('clinton', row['text'])
    trump += word_in_text('trump', row['text'])
    sanders += word_in_text('sanders', row['text'])
    cruz += word_in_text('cruz', row['text'])
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;Tiếp theo ta sẽ tạo list trong Python, mỗi item sẽ có giá trị đếm bắt đầu =0. Mục đích ở đây là để đếm số tweet count được cho mỗi keyword.&lt;/li&gt;
  &lt;li&gt;Sử dụng vòng lặp để đi từng row và check, nếu gặp keyword sẽ +1 vào biến đếm. Nếu True (nghĩa là có keyword đó) thì += 1.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;basic-data-visualization&quot;&gt;Basic Data visualization&lt;/h5&gt;

&lt;pre&gt;&lt;code&gt;# Import packages
import seaborn as sns
import matplotlib.pyplot as plt


# Set seaborn style
sns.set(color_codes=True)

# Create a list of labels:cd
cd = ['clinton', 'trump', 'sanders', 'cruz']

# Plot the bar chart
ax = sns.barplot(cd, [clinton, trump, sanders, cruz])
ax.set(ylabel=&quot;count&quot;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;Đầu tiên cần import 2 package như trên để vẽ biểu đồ&lt;/li&gt;
  &lt;li&gt;Hàm &lt;code&gt;sns.barplot()&lt;/code&gt; có 2 tham số:
    &lt;ul&gt;
      &lt;li&gt;Tham số đầu: list label cần biểu diễn giá trị&lt;/li&gt;
      &lt;li&gt;Tham số thứ 2: list chứa giá trị của các label cần biểu diễn. List này đã được khởi tạo và đếm ở code trước đó.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sun, 18 Jul 2021 00:00:00 +0700</pubDate>
        <link>http://localhost:5000/import-data-medium/</link>
        <guid isPermaLink="true">http://localhost:5000/import-data-medium/</guid>
        
        
        <category>Data</category>
        
      </item>
    
      <item>
        <title>Python - Part 1</title>
        <description>&lt;h4 id=&quot;i-list&quot;&gt;I. LIST&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Thêm phần tử cho list:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Chỉ cần + [list]&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;x = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;]
y = x + [&quot;e&quot;, &quot;f&quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
  &lt;li&gt;Xóa phần tử list:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dùng del(phần tử). Lưu ý là khi xóa thì các phần tử ở sau bị đẩy index lên.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;x = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;]
del(x[1])
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;Dấu [index:index] trong list
    &lt;ul&gt;
      &lt;li&gt;x[start:end]
  Với start là chỉ số lấy
  end chỉ số không lấy
Ví dụ:&lt;/li&gt;
      &lt;li&gt;x[2:5] : lấy giá trị của index từ 2 đến 4&lt;/li&gt;
      &lt;li&gt;x[:3] : từ đầu đến index 2&lt;/li&gt;
      &lt;li&gt;x[3:] : từ index 3 đến hết&lt;/li&gt;
      &lt;li&gt;x[:] : lấy hết phần tử&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dấu &lt;code&gt;;&lt;/code&gt;:
Dùng để tách command code trên cùng 1 dòng, nếu khác dòng thì không cần.
```
    &lt;h1 id=&quot;same-line&quot;&gt;Same line&lt;/h1&gt;
    &lt;p&gt;command1; command2&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;separate-lines&quot;&gt;Separate lines&lt;/h1&gt;
&lt;p&gt;command1
command2&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
* Copy list:
Khi copy kiểu ``x=y`` thì thực tế ta đang copy địa chỉ list của y cho x. Nghĩa là khi ta thay đổi phần tử trong x thì y cũng thay đổi theo.

Để xử lý tình huống này, nếu chỉ muốn copy giá trị list thì ta dùng: ``x = list(y)`` hoặc ``x = y[:]``


* Convert datatype
x = str(y)
x = int(y)
x = float(y)
&amp;gt; Check datatype bằng function ``type()``

* Xem cấu trúc của 1 function có sẵn:
``help(max)`` hoặc ``?max``

#### II. METHOD
* Cũng là function nhưng dành cho từng type
* Tất cả mọi thứ trong Python đều là object.
* Object có các method riêng, phụ thuộc vào data type 

#### III. Numpy
Tại sao dùng Numpy?
*  Rất quyền lực, có thể sử dụng cho nhiều data type khác nhau. Tuy nhiên mỗi tập hợp (array) chỉ được chứa 1 loại data type.
* Có thể thêm, xóa, sửa
* Quan trọng trong Data Science
	* Làm các phép toán cho các tập hợp
	* Tốc độ nhanh
* Ta thấy nếu áp dụng phép toán như -*/ trên kiểu dữ liệu list thì sẽ throw Error ``không hỗ trợ``. Nếu + thì sẽ ghép 2 list lại thành 1 list.
&amp;gt; Tuy nhiên, ta đang cần +-*/ trên 2 list theo index tương ứng. Thì Numpy sẽ giúp ta giải quyết khó khăn này.

Giải pháp Numpy có gì?
* Python kiểu số. Có hàm ``np.mean()`` và ``np.median()`` rất phổ biến trong data science.
* Thay thế cho Python List : kiểu dữ liệu ``Numpy Array``
* Giúp tính toán trên toàn bộ array
* Nhanh và dễ dàng
* Cài đặt trong terminal: 
``pip3 install numpy``

Như vậy, để thực hiện các phép toán trên list, ta phải chuyển nó sang kiểu dữ liệu Numpy Array như sau:
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;import numpy as np
np_height = np.array(height)
np_weight = np.array(weight)
bmi = np_weight / np_height ** 2&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
**Lưu ý quan trọng:**

* Mỗi array chỉ được chứa 1 loại data type.
* Type khác nhau thì hành vi của nó sẽ khác nhau. VD: 

	* Phép + 2 list thì là ghép 2 list thành 1. 
	* Phép + 2 array thì là cộng theo giá trị index tương ứng của 2 array với nhau.

##### 1. Numpy Subsetting 
* Ta có array ``bmi``.
* Để truy cập vào array ta dùng cú pháp: ``bmi[index]``
* Để xét các giá trị trong array có thỏa điều kiện không, ta dùng: ``bmi &amp;gt; 23``
&amp;gt; Trả về array có kiểu Boolean (True/False)
* Để trả về array chứa các giá trị thỏa điều kiện, ta dùng: ``bmi[bmi &amp;gt; 23]`` 

##### 2. Type của Numpy array
Nếu ``print(type(np_height))``
&amp;gt; numpy.ndarray

Với numpy là package, n là layer của array. ndarray là kiểu dữ liệu chỉ sử dụng trong Numpy.

##### 3. 2D Numpy Arrays 
Cách tạo 2D array bằng 2 array:
* array1
* array2
* meas = np.array([array1, array2])


Có thể xem 2D numpy array như phiên bản nâng cấp của &quot;list của list&quot; vì ta có thể thực hiện các phép toán với nó.

Để tạo array 2D, ta chỉ cần input các giá trị vào như dưới đây, input 1 list có 2 sub-list vào argument của method ``np.array`` theo cấu trúc hình chữ nhật:
![](img/2d-array.png)

Mỗi sub-list là một row của array.  
Nếu ta thay đổi kiểu dữ liệu của bất kỳ giá trị nào trong array sang kiểu khác như từ float sang string, thì mặc nhiên numpy sẽ chuyển tất cả các giá trị còn lại sang string (in ra sẽ thấy).
&amp;gt; Vì mỗi numpy array chỉ chứa 1 kiểu dữ liệu.

Để biết cấu trúc data của array như thế nào, ta dùng attribute ``shape`` của array:
![](img/array-shape.png)
 *Vì là attribute nên nó không có ``()`` như method~*

Có 2 cú pháp để truy cập giá trị:
![](img/2d-subset.png)

* Cách 1: np_2d[row][column]
* Cách 2: np_2d[row,column]
* Dấu ``:`` vẫn sẽ được sử dụng giống như 1D array ở trên nếu muốn chọn cụ thể vùng giá trị muốn lấy.

*Với row, column là index, chú ý ở đây vẫn sử dụng zero-index cho 2D array.*


##### 4. Toán tử Boolean trong Numpy
Với Numpy array ta có thể sử dụng phép so sánh như các ví dụ trên, nhưng nếu sử dụng kết hợp and, or, not thì sẽ throw Error.
Do vậy, ta phải sử dụng:

* np.logical_and()
* np.logical_or() 
* np.logical_not()

Ex:
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;np.logical_and(my_house &amp;gt; 13, 
               your_house &amp;lt; 15)&lt;/p&gt;

&lt;h1 id=&quot;kết-quả-trả-về-1-boolean-series-thích-hợp-dùng-để-filter-dataframe&quot;&gt;Kết quả trả về 1 Boolean Series, thích hợp dùng để filter dataframe&lt;/h1&gt;
&lt;p&gt;```
Với my_house và your_house là 2 Numpy array.&lt;/p&gt;
</description>
        <pubDate>Sun, 11 Jul 2021 00:00:00 +0700</pubDate>
        <link>http://localhost:5000/python-basic/</link>
        <guid isPermaLink="true">http://localhost:5000/python-basic/</guid>
        
        
        <category>Data</category>
        
        <category>Programing</category>
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>(ENG) The basics of Spark</title>
        <description>&lt;p&gt;Đầu tiên phải kết nối với &lt;code&gt;Cluster&lt;/code&gt;. &lt;code&gt;Cluster&lt;/code&gt; được host trên remote machine mà được connect với tất cả các node khác. Sẽ có 1 máy tính gọi là &lt;code&gt;master&lt;/code&gt; phụ trách việc bóc tách dữ liệu và tính toán. &lt;code&gt;master&lt;/code&gt; được kết nối với tất cả những máy tính còn lại trong cluster, các máy tính còn lại gọi là &lt;code&gt;worker&lt;/code&gt;. &lt;code&gt;master&lt;/code&gt; gửi cho &lt;code&gt;workers&lt;/code&gt; data và các phép toán để chạy và chúng sẽ trả về cho &lt;code&gt;master&lt;/code&gt; kết quả.&lt;br /&gt;
The first step in using Spark is connecting to a cluster.&lt;/p&gt;

&lt;p&gt;In practice, the cluster will be hosted on a remote machine that’s connected to all other nodes. There will be one computer, called the master that manages splitting up the data and the computations. The master is connected to the rest of the computers in the cluster, which are called worker. The master sends the workers data and calculations to run, and they send their results back to the master.&lt;/p&gt;

&lt;p&gt;Deciding whether or not Spark is the best solution for your problem takes some experience, but you can consider questions like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Is my data too big to work with on a single machine?
Can my calculations be easily parallelized?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Bước 1: Create an instance of the SparkContext class to connect to a Spark cluster from PySpark.The class constructor takes a few optional arguments that allow you to specify the attributes of the cluster you’re connecting to.&lt;/p&gt;

&lt;p&gt;An object holding all these attributes can be created with the SparkConf() constructor. Take a look at the documentation for all the details! You can think of the SparkContext as your connection to the cluster and the SparkSession as your interface with that connection.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from pyspark.sql import SparkSession, SQLContext

# Create SparkSession. Creating multiple SparkSessions and SparkContexts can cause issues, so it's best practice to use the SparkSession.builder.getOrCreate() method. This returns an existing SparkSession if there's already one in the environment, or creates a new one if necessary!
spark = SparkSession.builder.appName(&quot;CAR DAILY&quot;).getOrCreate()

# Create sparkContext
sc = spark.sparkContext

sqlContext = SQLContext(sc)

# Verify SparkContext
print(sc)

# Print Spark version
print(sc.version)

&amp;lt;SparkContext master=local[*] appName=pyspark-shell&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You may also find that running simpler computations might take longer than expected. That’s because all the optimizations that Spark has under its hood are designed for complicated operations with big data sets. That means that for simple or small problems Spark may actually perform worse than some other solutions!&lt;/p&gt;

&lt;h4 id=&quot;using-dataframes&quot;&gt;Using DataFrames&lt;/h4&gt;

&lt;p&gt;Spark’s core data structure is the Resilient Distributed Dataset (RDD). This is a low level object that lets Spark work its magic by splitting data across multiple nodes in the cluster. However, RDDs are hard to work with directly, so in this course you’ll be using the Spark DataFrame abstraction built on top of RDDs.&lt;/p&gt;

&lt;p&gt;The Spark DataFrame was designed to behave a lot like a SQL table (a table with variables in the columns and observations in the rows). Not only are they easier to understand, DataFrames are also more optimized for complicated operations than RDDs.&lt;/p&gt;

&lt;p&gt;When you start modifying and combining columns and rows of data, there are many ways to arrive at the same result, but some often take much longer than others. When using RDDs, it’s up to the data scientist to figure out the right way to optimize the query, but the DataFrame implementation has much of this optimization built in!&lt;/p&gt;

&lt;p&gt;To start working with Spark DataFrames, you first have to create a SparkSession object from your SparkContext. You can think of the SparkContext as your connection to the cluster and the SparkSession as your interface with that connection.&lt;/p&gt;

&lt;hr /&gt;

&lt;h5 id=&quot;i-select&quot;&gt;I. SELECT&lt;/h5&gt;

&lt;blockquote&gt;
  &lt;p&gt;flights.select(flights.air_time/60)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;returns a column of flight durations in hours instead of minutes.&lt;/p&gt;

&lt;p&gt;if you wanted to .select() the column duration_hrs (which isn’t in your DataFrame) you could do&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;flights.select((flights.air_time/60).alias(“duration_hrs”))&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The equivalent Spark DataFrame method .selectExpr() takes SQL expressions as a string:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;flights.selectExpr(“air_time/60 as duration_hrs”)
with the SQL as keyword being equivalent to the .alias() method. To select multiple columns, you can pass multiple strings.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;View tables:
Once you’ve created a SparkSession, you can start poking around to see what data is in your cluster!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Your SparkSession has an attribute called catalog which lists all the data inside the cluster. This attribute has a few methods for extracting different pieces of information.&lt;/p&gt;

&lt;p&gt;One of the most useful is the .listTables() method, which returns the names of all the tables in your cluster as a list.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spark.catalog.listTables()
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;Querying:
Running a query on this table is as easy as using the .sql() method on your SparkSession. This method takes a string containing the query and returns a DataFrame with the results!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you look closely, you’ll notice that the table flights dataframe is only mentioned in the query, not as an argument to any of the methods. This is because there isn’t a local object in your environment that holds that data, so it wouldn’t make sense to pass the table as an argument.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Convert Spark DF to Pandas DF - Pandafy a Spark DataFrame&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Suppose you’ve run a query on your huge dataset and aggregated it down to something a little more manageable.&lt;/p&gt;

&lt;p&gt;Sometimes it makes sense to then take that table and work with it locally using a tool like pandas. Spark DataFrames make that easy with the .toPandas() method. Calling this method on a Spark DataFrame returns the corresponding pandas DataFrame. It’s as simple as that!&lt;/p&gt;

&lt;p&gt;This time the query counts the number of flights to each airport from SEA and PDX.&lt;/p&gt;

&lt;p&gt;Remember, there’s already a SparkSession called spark in your workspace!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Don't change this query
query = &quot;SELECT origin, dest, COUNT(*) as N FROM flights GROUP BY origin, dest&quot;

# Run the query
flight_counts = spark.sql(query)

# Convert the results to a pandas DataFrame
pd_counts = flight_counts.toPandas()

# Print the head of pd_counts
print(pd_counts.head())
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&quot;convert-from-pandas-df-to-spark-df---put-some-spark-in-your-data&quot;&gt;Convert from Pandas DF to Spark DF - Put some Spark in your data&lt;/h5&gt;

&lt;p&gt;In the last exercise, you saw how to move data from Spark to pandas. However, maybe you want to go the other direction, and put a pandas DataFrame into a Spark cluster! The SparkSession class has a method for this as well.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;.createDataFrame()&lt;/code&gt; method takes a pandas DataFrame and returns a Spark DataFrame.&lt;/p&gt;

&lt;p&gt;The output of this method is stored locally, not in the SparkSession catalog. This means that you can use all the Spark DataFrame methods on it, but you can’t access the data in other contexts.&lt;/p&gt;

&lt;p&gt;For example, a SQL query (using the .sql() method) that references your DataFrame will throw an error. To access the data in this way, you have to save it as a temporary table.&lt;/p&gt;

&lt;p&gt;You can do this using the &lt;code&gt;.createTempView()&lt;/code&gt; Spark DataFrame method, which takes as its only argument the name of the temporary table you’d like to register. This method registers the DataFrame as a table in the catalog, but as this table is temporary, it can only be accessed from the specific SparkSession used to create the Spark DataFrame.&lt;/p&gt;

&lt;p&gt;There is also the method .createOrReplaceTempView(). This safely creates a new temporary table if nothing was there before, or updates an existing table if one was already defined. You’ll use this method to avoid running into problems with duplicate tables.&lt;/p&gt;

&lt;p&gt;Giải thích thêm: Trong 1 SparkSession có nhiều SparkContext như sql(),… Trong SparkSession nó có method giúp chuyển đổi từ Pandas DF thành Spark DF.
Spark Dataframe tạo ra từ .createDataFrame() cho kết quả về được lưu locally nhưng không được lưu vào SparkSession catalog. Khi đó ta không thể truy cập từ các context khác nhau trong cùng SparkSession như không thể query .sql(). 
Do vậy sau khi dùng method trên, ta dùng .createTempView() là method dành cho Spark DF để đăng ký Spark DF này thành 1 temporary table trong catalog và có thể sử dụng chung cho các context khác nhau. Tuy nhiên, vì là temporary nên Spark DF này không dùng chung được cho các SparkSession khác nhau mà chỉ dùng cho Session mà tạo ra nó. Ngoài ra, .createOrReplaceTempView() tương tự method tạo temp table nhưng nó giúp tránh duplicate table nếu như nó đã có tạo rồi thì update.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; # Create pd_temp
pd_temp = pd.DataFrame(np.random.random(10))

# Create spark_temp from pd_temp
spark_temp = spark.createDataFrame(pd_temp)

# Examine the tables in the catalog
spark.catalog.listTables()

# Add spark_temp to the catalog
spark_temp.createOrReplaceTempView(&quot;temp&quot;)

# Examine the tables in the catalog again
print(spark.catalog.listTables())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Xem cách các Spark data structure tương tác với nhau bằng nhiều cách trong biểu đồ dưới đây:
&lt;img src=&quot;img/spark-structure.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;convert-thành-spark-df-trực-tiếp-từ-file-csv-mà-không-cần-thông-qua-pandas-df&quot;&gt;Convert thành Spark DF trực tiếp từ file .csv mà không cần thông qua pandas DF:&lt;/h5&gt;
&lt;p&gt;Now you know how to put data into Spark via pandas, but you’re probably wondering why deal with pandas at all? Wouldn’t it be easier to just read a text file straight into Spark? Of course it would!&lt;/p&gt;

&lt;p&gt;Luckily, your SparkSession has a .read attribute which has several methods for reading different data sources into Spark DataFrames. Using these you can create a DataFrame from a .csv file just like with regular pandas DataFrames!&lt;/p&gt;

&lt;p&gt;The variable file_path is a string with the path to the file airports.csv. This file contains information about different airports all over the world.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Don't change this file path
file_path = &quot;/usr/local/share/datasets/airports.csv&quot;

# Read in the airports data
airports = spark.read.csv(file_path, header=True)

# Show the data
airport.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&quot;creating-columns&quot;&gt;Creating columns&lt;/h5&gt;

&lt;p&gt;In this chapter, you’ll learn how to use the methods defined by Spark’s DataFrame class to perform common data operations.&lt;/p&gt;

&lt;p&gt;Let’s look at performing column-wise operations. In Spark you can do this using the &lt;code&gt;.withColumn()&lt;/code&gt; method, which takes two arguments. First, a string with the name of your new column, and second the new column itself.&lt;/p&gt;

&lt;p&gt;The new column must be an object of class Column. Creating one of these is as easy as extracting a column from your DataFrame using &lt;code&gt;df.colName&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Updating a Spark DataFrame is somewhat different than working in pandas because the Spark DataFrame is immutable. This means that it can’t be changed, and so columns can’t be updated in place.&lt;/p&gt;

&lt;p&gt;Thus, all these methods return a new DataFrame. To overwrite the original DataFrame you must reassign the returned DataFrame using the method like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;df = df.withColumn(&quot;newCol&quot;, df.oldCol + 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above code creates a DataFrame with the same columns as df plus a new column, newCol, where every entry is equal to the corresponding entry from oldCol, plus one.&lt;/p&gt;

&lt;p&gt;To overwrite an existing column, just pass the name of the column as the first argument!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Create the DataFrame flights
flights = spark.table(&quot;flights&quot;)

# Show the head
flights.show()

# Add duration_hrs
flights = flights.withColumn(&quot;duration_hrs&quot;, flights.air_time/60)

flights.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Use the spark.table() method with the argument &quot;flights&quot; to create a DataFrame containing the values of the flights table in the .catalog. Save it as flights.
Show the head of flights using flights.show(). Check the output: the column air_time contains the duration of the flight in minutes.
Update flights to include a new column called duration_hrs, that contains the duration of each flight in hours (you'll need to divide duration_hrs by the number of minutes in an hour).
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&quot;filtering-data&quot;&gt;Filtering Data&lt;/h5&gt;

&lt;p&gt;Now that you have a bit of SQL know-how under your belt, it’s easier to talk about the analogous operations using Spark DataFrames.&lt;/p&gt;

&lt;p&gt;Let’s take a look at the .filter() method. As you might suspect, this is the Spark counterpart of SQL’s WHERE clause. The .filter() method takes either an expression that would follow the WHERE clause of a SQL expression as a string, or a Spark Column of boolean (True/False) values.&lt;/p&gt;

&lt;p&gt;For example, the following two expressions will produce the same output:&lt;/p&gt;

&lt;p&gt;flights.filter(“air_time &amp;gt; 120”).show()
flights.filter(flights.air_time &amp;gt; 120).show()&lt;/p&gt;

&lt;p&gt;Notice that in the first case, we pass a string to .filter(). In SQL, we would write this filtering task as SELECT * FROM flights WHERE air_time &amp;gt; 120. Spark’s .filter() can accept any expression that could go in the WHEREclause of a SQL query (in this case, “air_time &amp;gt; 120”), as long as it is passed as a string. Notice that in this case, we do not reference the name of the table in the string – as we wouldn’t in the SQL request.&lt;/p&gt;

&lt;p&gt;In the second case, we actually pass a column of boolean values to .filter(). Remember that flights.air_time &amp;gt; 120 returns a column of boolean values that has True in place of those records in flights.air_time that are over 120, and False otherwise.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Filter flights by passing a string
long_flights1 = flights.filter(&quot;distance &amp;gt; 1000&quot;)

# Filter flights by passing a column of boolean values
long_flights2 = flights.filter(flights.distance &amp;gt; 1000)

# Print the data to check they're equal
long_flights1.show()
long_flights2.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;=&amp;gt; Kết quả như nhau&lt;/p&gt;

&lt;h5 id=&quot;selecting&quot;&gt;Selecting&lt;/h5&gt;

&lt;p&gt;The Spark variant of SQL’s SELECT is the .select() method. This method takes multiple arguments - one for each column you want to select. These arguments can either be the column name as a string (one for each column) or a column object (using the df.colName syntax). When you pass a column object, you can perform operations like addition or subtraction on the column to change the data contained in it, much like inside .withColumn().&lt;/p&gt;

&lt;p&gt;The difference between .select() and .withColumn() methods is that .select() returns only the columns you specify, while .withColumn() returns all the columns of the DataFrame in addition to the one you defined. It’s often a good idea to drop columns you don’t need at the beginning of an operation so that you’re not dragging around extra data as you’re wrangling. In this case, you would use .select() and not .withColumn().&lt;/p&gt;

&lt;p&gt;Remember, a SparkSession called spark is already in your workspace, along with the Spark DataFrame flights.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Select the first set of columns
selected1 = flights.select(&quot;tailnum&quot;, &quot;origin&quot;,&quot;dest&quot;)

# Select the second set of columns
temp = flights.select(flights.origin, flights.dest, flights.carrier)

# Define first filter
filterA = flights.origin == &quot;SEA&quot;

# Define second filter
filterB = flights.dest == &quot;PDX&quot;

# Filter the data, first by filterA then by filterB
selected2 = temp.filter(filterA).filter(filterB)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Select the columns “tailnum”, “origin”, and “dest” from flights by passing the column names as strings. Save this as selected1.&lt;/p&gt;

&lt;p&gt;Select the columns “origin”, “dest”, and “carrier” using the df.colName syntax and then filter the result using both of the filters already defined for you (filterA and filterB) to only keep flights from SEA to PDX. Save this as selected2.&lt;/p&gt;

&lt;h5 id=&quot;selecting-ii&quot;&gt;Selecting II&lt;/h5&gt;

&lt;p&gt;Similar to SQL, you can also use the .select() method to perform column-wise operations. When you’re selecting a column using the df.colName notation, you can perform any column operation and the .select() method will return the transformed column. For example,&lt;/p&gt;

&lt;p&gt;flights.select(flights.air_time/60)&lt;/p&gt;

&lt;p&gt;returns a column of flight durations in hours instead of minutes. You can also use the .alias() method to rename a column you’re selecting. So if you wanted to .select() the column duration_hrs (which isn’t in your DataFrame) you could do&lt;/p&gt;

&lt;p&gt;&lt;code&gt;flights.select((flights.air_time/60).alias(&quot;duration_hrs&quot;))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The equivalent Spark DataFrame method .selectExpr() takes SQL expressions as a string:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;flights.selectExpr(&quot;air_time/60 as duration_hrs&quot;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;with the SQL as keyword being equivalent to the .alias() method. To select multiple columns, you can pass multiple strings.&lt;/p&gt;

&lt;p&gt;Remember, a SparkSession called spark is already in your workspace, along with the Spark DataFrame flights.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Define avg_speed
avg_speed = (flights.distance/(flights.air_time/60)).alias(&quot;avg_speed&quot;)

# Select the correct columns
speed1 = flights.select(&quot;origin&quot;, &quot;dest&quot;, &quot;tailnum&quot;, avg_speed)

# Create the same table using a SQL expression
speed2 = flights.selectExpr(&quot;origin&quot;, &quot;dest&quot;, &quot;tailnum&quot;, &quot;distance/(air_time/60) as avg_speed&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&quot;aggregating&quot;&gt;Aggregating&lt;/h5&gt;

&lt;p&gt;All of the common aggregation methods, like .min(), .max(), and .count() are GroupedData methods. These are created by calling the .groupBy() DataFrame method. You’ll learn exactly what that means in a few exercises. For now, all you have to do to use these functions is call that method on your DataFrame. For example, to find the minimum value of a column, col, in a DataFrame, df, you could do&lt;/p&gt;

&lt;p&gt;&lt;code&gt;df.groupBy().min(&quot;col&quot;).show()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This creates a GroupedData object (so you can use the .min() method), then finds the minimum value in col, and returns it as a DataFrame.&lt;/p&gt;

&lt;p&gt;Now you’re ready to do some aggregating of your own!&lt;/p&gt;

&lt;p&gt;A SparkSession called spark is already in your workspace, along with the Spark DataFrame flights.&lt;/p&gt;

&lt;p&gt;Ex:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;flights.show()

# Find the shortest flight from PDX in terms of distance
flights.filter(flights.origin == &quot;PDX&quot;).groupBy().min(&quot;distance&quot;).show()

# Find the longest flight from SEA in terms of air time
flights.filter(flights.origin == &quot;SEA&quot;).groupBy().max(&quot;air_time&quot;).show()
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&quot;grouping-and-aggregating-i&quot;&gt;Grouping and Aggregating I&lt;/h5&gt;

&lt;p&gt;Part of what makes aggregating so powerful is the addition of groups. PySpark has a whole class devoted to grouped data frames: pyspark.sql.GroupedData, which you saw in the last two exercises.&lt;/p&gt;

&lt;p&gt;You’ve learned how to create a grouped DataFrame by calling the .groupBy() method on a DataFrame with no arguments.&lt;/p&gt;

&lt;p&gt;Now you’ll see that when you pass the name of one or more columns in your DataFrame to the .groupBy() method, the aggregation methods behave like when you use a GROUP BY statement in a SQL query!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Group by tailnum
by_plane = flights.groupBy(&quot;tailnum&quot;)

# Number of flights each plane made
by_plane.count().show()

# Group by origin
by_origin = flights.groupBy(&quot;origin&quot;)

# Average duration of flights from PDX and SEA
by_origin.avg(&quot;air_time&quot;).show()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Create a DataFrame called by_plane that is grouped by the column tailnum.
Use the .count() method with no arguments to count the number of flights each plane made.
Create a DataFrame called by_origin that is grouped by the column origin.
Find the .avg() of the air_time column to find average duration of flights from PDX and SEA.
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&quot;grouping-and-aggregating-ii&quot;&gt;Grouping and Aggregating II&lt;/h5&gt;

&lt;p&gt;In addition to the GroupedData methods you’ve already seen, there is also the .agg() method. This method lets you pass an aggregate column expression that uses any of the aggregate functions from the pyspark.sql.functions submodule.&lt;/p&gt;

&lt;p&gt;This submodule contains many useful functions for computing things like standard deviations. All the aggregation functions in this submodule take the name of a column in a GroupedData table.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Import pyspark.sql.functions as F
import pyspark.sql.functions as F

# Group by month and dest
by_month_dest = flights.groupBy(&quot;month&quot;, &quot;dest&quot;)

# Average departure delay by month and destination
by_month_dest.avg(&quot;dep_delay&quot;).show()

# Standard deviation of departure delay
by_month_dest.agg(F.stddev(&quot;dep_delay&quot;)).show()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Import the submodule pyspark.sql.functions as F.
Create a GroupedData table called by_month_dest that's grouped by both the month and dest columns. Refer to the two columns by passing both strings as separate arguments.
Use the .avg() method on the by_month_dest DataFrame to get the average dep_delay in each month for each destination.
Find the standard deviation of dep_delay by using the .agg() method with the function F.stddev().
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&quot;joining&quot;&gt;Joining&lt;/h5&gt;

&lt;p&gt;In PySpark, joins are performed using the DataFrame method .join(). This method takes three arguments. The first is the second DataFrame that you want to join with the first one. The second argument, on, is the name of the key column(s) as a string. The names of the key column(s) must be the same in each table. The third argument, how, specifies the kind of join to perform. In this course we’ll always use the value how=”leftouter”.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Examine the data
print(airports.show())
print(flights.show())

# Rename the faa column
airports = airports.withColumnRenamed(&quot;faa&quot;, &quot;dest&quot;)

# Join the DataFrames
flights_with_airports = flights.join(airports,&quot;dest&quot;,how=&quot;leftouter&quot;)

# Examine the new DataFrame
print(flights_with_airports.show())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Examine the airports DataFrame by calling .show(). Note which key column will let you join airports to the flights table.
    Rename the faa column in airports to dest by re-assigning the result of airports.withColumnRenamed(“faa”, “dest”) to airports.
    Join the flights with the airports DataFrame on the dest column by calling the .join() method on flights. Save the result as flights_with_airports.
        The first argument should be the other DataFrame, airports.
        The argument on should be the key column.
        The argument how should be “leftouter”.
    Call .show() on flights_with_airports to examine the data again. Note the new information that has been added.&lt;/p&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;machine-learning-pipeline&quot;&gt;Machine Learning Pipeline&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;Learn more at: http://spark.apache.org/docs/2.1.0/api/python/pyspark.html&lt;/p&gt;

</description>
        <pubDate>Sun, 27 Jun 2021 00:00:00 +0700</pubDate>
        <link>http://localhost:5000/spark/</link>
        <guid isPermaLink="true">http://localhost:5000/spark/</guid>
        
        
        <category>Data</category>
        
      </item>
    
      <item>
        <title>Data Visualization</title>
        <description>&lt;h4 id=&quot;1-các-loại-chart-cơ-bản&quot;&gt;1. Các loại chart cơ bản&lt;/h4&gt;

&lt;p&gt;BAR CHART &amp;amp; COLUMN CHART&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Giúp ta nhìn vào giá trị cụ thể cho mỗi loại&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Có 4 loại:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Stacked bar và column chart
    &lt;blockquote&gt;
      &lt;p&gt;Biểu đồ chồng nhau theo giá trị,&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;Clustered bar và column chart
    &lt;blockquote&gt;
      &lt;p&gt;Biểu đồ nhiều cột trong 1 phân loại&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;100% stacked bar và column chart
    &lt;blockquote&gt;
      &lt;p&gt;Biểu đồ chồng theo %&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;Combo chart
    &lt;blockquote&gt;
      &lt;p&gt;Biểu đồ kết hợp cột và biểu đồ đường&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;LINE CHART&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Giúp biểu diễn chuỗi giá trị theo dạng có hình, thường là thông qua diễn tiến thay đổi của thời gian&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;AREA CHART&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Dựa trên Line chart nhưng được fill màu&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;PIE CHART &amp;amp; DONUT CHART&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Biểu diễn mỗi quan hệ giữa các thành phần và tổng thể&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;TREE MAP&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Biểu diễn mỗi quan hệ giữa các thành phần và tổng thể, với các hình vuông có màu có kích cỡ riêng biểu thị phần mà các giá trị chiếm.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;CARD &amp;amp; MULTI-ROW CARD&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Card
    &lt;blockquote&gt;
      &lt;p&gt;biểu diễn 1 giá trị&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;*Multi-row card&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;dùng để biểu diễn nhiều giá trị&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;GAUGE CHART &amp;amp; KPI&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;được thiết kế để hiển thị dữ liệu thực tế so sánh với dữ liệu ngân sách/doanh thu hoặc mục tiêu đã lên kế hoạch.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;TABLE &amp;amp; MATRIX&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;biểu diễn chi tiết dữ liệu văn bản bằng định dạng Bảng&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Table:
    &lt;blockquote&gt;
      &lt;p&gt;chứa dữ liệu liên quan trong chuỗi logical của dòng và cột, có thể bao gồm header &amp;amp; footer của bảng&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;Matrix:
    &lt;blockquote&gt;
      &lt;p&gt;giống như bảng nhưng matrix có thể thu lại hoặc mở rộng ra bằng dòng hoặc cột&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;HIERARCHIES:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Level data từ cao đến thấp&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ví dụ:
Year =&amp;gt; Quarter =&amp;gt; Month =&amp;gt; Day
Company =&amp;gt; Region =&amp;gt; Country =&amp;gt; DIvision =&amp;gt; Unit&lt;/p&gt;

&lt;p&gt;HÀM:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Là các công thức được định nghĩa trước sẵn để biểu diễn các phép tính trên các giá trị gọi là tham trị &lt;code&gt;arguments&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;2-kiến-thức-nền-tảng-để-visualize-data&quot;&gt;2. Kiến thức nền tảng để visualize data&lt;/h4&gt;

&lt;p&gt;Có 3 cách để lấy được insight của data:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Cách 1: Tính toán thống kê
mean (trung bình), median(trung vị), standard deviation (phương sai)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cách 2: Run model/Chạy mô hình
Linear (Tuyến tính) hoặc hồi quy logistic&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cách 3: Vẽ plot
scatter, bar, histogram (biểu đồ tần suất),…
Scatter plot:
&lt;img src=&quot;img/plot.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;the-datasaurus-dozen&quot;&gt;The Datasaurus Dozen&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;img/datasaurus-dozen.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Có 13 datasets, mỗi Dataset có 2 trục x và y được gọi là variable&lt;/li&gt;
  &lt;li&gt;Variable đơn giản chỉ là biệt ngữ thống kê để chỉ cột dữ liệu&lt;/li&gt;
  &lt;li&gt;Khi tính phương sai của mỗi dataset, ta sẽ tính ra 2 phương sai cho x và y trên tất cả các record. Vì dataset trên có 2 giá trị x và y.&lt;/li&gt;
  &lt;li&gt;Phương sai dùng để tính toán sự biến thiên của dữ liệu.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;chọn-biểu-đồ-chấm-plot-loại-gì-thì-phù-hợp&quot;&gt;Chọn biểu đồ chấm plot loại gì thì phù hợp?&lt;/h5&gt;

&lt;p&gt;Trước tiên phải xác định variable x và y của data thuộc loại nào. Có 3 loại:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Continuous : thường là số và có thể làm các phép toán cho nó.
Ví dụ như nhiệt độ, chiều cao, doanh thu,…&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Categorical : thường là dạng văn bản text, những thứ được phân loại hay mô tả.
Ví dụ như màu mắt, quốc gia,…&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cả hai loại trên
Ví dụ như tuổi thì dạng continuous, còn nhóm tuổi từ 25-30 thì lại là categorical.
Thời gian thì continuous còn tháng thì categorical.&lt;/p&gt;
    &lt;blockquote&gt;
      &lt;p&gt;Ở đây tùy vào mục đích visualization mà bạn sẽ quyết định nó thuộc loại nào cho phù hợp.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;khi-nào-nên-dùng-biểu-đồ-tần-suất-histogram&quot;&gt;Khi nào nên dùng biểu đồ tần suất Histogram?&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Nếu bạn có biến continuous như trên&lt;/li&gt;
  &lt;li&gt;Khi bạn muốn biết hình dạng của sự phân tán data, ví dụ như bạn muốn biểu đồ thể hiện rõ giá trị cao nhất và thấp nhất.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Một số thuật ngữ:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Bin (interval) : khoảng cách các ô trục trên biểu đồ, ví dụ 0-5, 5-10,… Nếu muốn rõ data hơn thì ta co bin lại 0-1, 1-2,…
Như hình, bin 10-15 tuổi có giá trị trục y là 4, nghĩa là có 4 người từ 10-15 tuổi.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;img/histogram.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Sự lựa chọn binwidth sẽ ảnh hưởng lớn đến hình ảnh biểu đồ. Dưới đây cho thấy nếu thu nhỏ bin lại còn 1 năm tuổi thì nhìn rất lộn xộn.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/binwidth1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Các tiêu chí trải nghiệm qua để chọn binwidth phù hợp:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Modality : có bao nhiêu đỉnh trong biểu đồ?
Unimodal, bimodal hay trimodal?
&lt;img src=&quot;img/modality.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Skewness: lệch lạc hay cân xứng?
lệch trái, phải hay cân đối ở giữa?
&lt;img src=&quot;img/skewness.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kurtosis: có bao nhiêu điểm có giá trị = 0? (extreme value) 
&lt;img src=&quot;img/kurtosis.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;khi-nào-nên-vẽ-box-plots&quot;&gt;Khi nào nên vẽ Box Plots?&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;Khi chúng ta có 1 variable là continuous, được tách ra phân loại bởi 1 variable categorical.&lt;/li&gt;
  &lt;li&gt;Khi chúng ta muốn so sánh sự phân tán dữ liệu của variable continuous cho mỗi category (phân loại).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;img/box-plot.png&quot; alt=&quot;&quot; /&gt;
Các chỉ số trên box plots:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;lower quartile: 1/4 có giá trị dưới số này&lt;/li&gt;
  &lt;li&gt;median : trung vị&lt;/li&gt;
  &lt;li&gt;upper quartile: 1/4 có giá trị trên số này&lt;/li&gt;
  &lt;li&gt;inter-quartile range: khoảng cách từ lower đến upper&lt;/li&gt;
  &lt;li&gt;whiskers: đường thẳng ngang hai bên, đường kẻ ra gấp 1-1,5 lần inter-quarter, dài đến mức độ đủ để biết rằng ngoài đường kẻ thì không có giá trị nào cả (extreme value).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;img/box-plot-2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Phân loại nào chỉ có đường thẳng nghĩa là chỉ có 1 giá trị.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Wed, 23 Jun 2021 00:00:00 +0700</pubDate>
        <link>http://localhost:5000/data-visualization/</link>
        <guid isPermaLink="true">http://localhost:5000/data-visualization/</guid>
        
        
        <category>Data</category>
        
      </item>
    
      <item>
        <title>Set-up phpMyAdmin</title>
        <description>&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Initial setup with Ubuntu 20.4: 
https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Install Mysql on Ubuntu 20.4:
https://www.digitalocean.com/community/tutorials/how-to-install-mysql-on-ubuntu-20-04&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Install LAMP (Linux, Apache, MySQL, PHP)
https://www.digitalocean.com/community/tutorials/how-to-install-linux-apache-mysql-php-lamp-stack-on-ubuntu-20-04&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Install and Secure phpMyAdmin:
https://www.digitalocean.com/community/tutorials/how-to-install-and-secure-phpmyadmin-on-ubuntu-20-04&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Secure Apache with Let’s Encrypt on Ubuntu 20.04 (free TLS/SSL certificate)
https://www.digitalocean.com/community/tutorials/how-to-secure-apache-with-let-s-encrypt-on-ubuntu-20-04&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;DOCKER COMPOSE &amp;amp; NETWORK
https://vsudo.net/blog/docker-toan-tap.html&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt; CÓ 2 CÁCH ĐỂ SỬ DỤNG phpMyAdmin:
C1: cài đặt thủ công và sử dụng trên localhost hoặc domain trên server mình host (xem link trên)
https://www.digitalocean.com/community/tutorials/how-to-install-and-secure-phpmyadmin-on-ubuntu-20-04 =&amp;gt; đã thử và ok

C2:dùng Docker network chứa 2 container là MySQL và phpMyAdmin để truy cập MySQL server trên phpMyAdmin host
https://vsudo.net/blog/docker-toan-tap.html =&amp;gt; đã thử và ok

&lt;h3&gt; Cách để đưa db của mình chạy trên container có sẵn của phpMyAdmin
B1: tạo image chạy trên base php cho file .php chứa truy vấn bảng của db (như 1 ứng dụng) và phải cài đặt biến môi trường trong này cho giống với config của container.
B2: compose với container của phpMyAdmin có sẵn (có thể chọn các image phù hợp nhu cầu) và bổ sung image ở trên vào file docker-compose.yml 


--------------------------------------------------


WORKDIR /var/www/tuyen.tech

COPY /etc/apache2/sites-available/tuyen.tech.conf /etc/apache2/sites-available/
COPY /etc/apache2/conf-available/phpmyadmin.conf /etc/apache2/conf-available/
COPY /usr/share/phpmyadmin/.htaccess /usr/share/phpmyadmin/

COPY . /var/www/tuyen.tech/

RUN sudo apt update &amp;amp;&amp;amp; apt install -y \
&amp;amp;&amp;amp; apache2 \
&amp;amp;&amp;amp; php libapache2-mod-php php-mysql \
&amp;amp;&amp;amp; mysql-server \
&amp;amp;&amp;amp; phpmyadmin php-mbstring php-zip php-gd php-json php-curl \
&amp;amp;&amp;amp; phpmyadmin 

RUN sudo mysql_secure_installation \
&amp;amp;&amp;amp; sudo mysql \
&amp;amp;&amp;amp; sudo phpenmod mbstring \
&amp;amp;&amp;amp; sudo htpasswd -c /etc/phpmyadmin/.htpasswd tuyen \
&amp;amp;&amp;amp; sudo systemctl restart apache2 

EXPOSE 9090


--------------------------
FROM ubuntu:latest

MAINTAINER tuyennnt &amp;lt;tuyendev96@gmail.com&amp;gt;
WORKDIR /var/www/tuyen.tech

COPY /etc/apache2/sites-available/tuyen.tech.conf /etc/apache2/sites-available/
COPY /etc/apache2/conf-available/phpmyadmin.conf /etc/apache2/conf-available/
COPY /usr/share/phpmyadmin/.htaccess /usr/share/phpmyadmin/

COPY . /var/www/tuyen.tech/

RUN sudo apt update &amp;amp;&amp;amp; apt install -y \
&amp;amp;&amp;amp; apache2 \
&amp;amp;&amp;amp; php libapache2-mod-php php-mysql \
&amp;amp;&amp;amp; mysql-server \
&amp;amp;&amp;amp; phpmyadmin php-mbstring php-zip php-gd php-json php-curl \
&amp;amp;&amp;amp; phpmyadmin 

RUN sudo mysql_secure_installation \
&amp;amp;&amp;amp; sudo mysql \
&amp;amp;&amp;amp; sudo phpenmod mbstring \
&amp;amp;&amp;amp; sudo htpasswd -c /etc/phpmyadmin/.htpasswd tuyen \
&amp;amp;&amp;amp; sudo systemctl restart apache2 

EXPOSE 9090

&lt;/h3&gt;&lt;/h3&gt;
</description>
        <pubDate>Tue, 15 Jun 2021 00:00:00 +0700</pubDate>
        <link>http://localhost:5000/phpmyadmin/</link>
        <guid isPermaLink="true">http://localhost:5000/phpmyadmin/</guid>
        
        
        <category>Data</category>
        
        <category>Docker</category>
        
      </item>
    
      <item>
        <title>Extract - Transform - Load (ETL process)</title>
        <description>&lt;h1 id=&quot;tìm-hiểu-về-etl&quot;&gt;Tìm hiểu về ETL&lt;/h1&gt;

&lt;h2 id=&quot;i-extract-data&quot;&gt;I. EXTRACT DATA&lt;/h2&gt;

&lt;h3 id=&quot;1-các-cách-để-trích-xuất-dữ-liệu&quot;&gt;1. Các cách để trích xuất dữ liệu&lt;/h3&gt;
&lt;p&gt;Có 3 cách:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/extract.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Trích xuất từ file text, như file .txt or .csv
Text file có 3 loại là : 
	* Text thuần
	* Flat file (là file có .tsv hoặc .csv cách nhau bởi dấu “,” hoặc “tab” giữa các giá trị). Những file này có dòng thể hiện các record và cột thể hiện attribute của record.
	*File JSON: bán cấu trúc, có 4 kiểu dữ liệu atomic là number, string, boolean và null và 2 kiểu dữ liệu dạng composite là array và object.
	JSON có package hỗ trợ là “json” để import data
	&lt;img src=&quot;img/load-json.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Trích xuất từ web hoặc APIs của web services, như là Hacker News API
&lt;img src=&quot;img/web-extract.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Thông qua web:&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;img/data-web.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ví dụ: bạn tìm kiếm thông tin trên google.com thì trình duyệt của bạn sẽ gửi request của bạn đến server của google và google sẽ trả về dữ liệu mà bạn đang tìm kiếm.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* Thông qua API của web:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Không phải lúc nào các trang web cũng trả về kết quả mà người thường có thể đọc ngay, mà các trang web đó sẽ trả về định dạng JSON thông qua API mà chúng ta request.&lt;/p&gt;

&lt;p&gt;Ta xem ví dụ request API từ trang Hackernews:
&lt;img src=&quot;img/api-request.png&quot; alt=&quot;&quot; /&gt;
Ta import package “request” rồi dùng method .get() để chèn vào link web cần lấy file JSON. 
Sau đó ta dùng method .json() để phân tích file JSON từ kết quả đã lấy được và chuyển hóa nó thành Python object.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Trích xuất từ một database trên web services 
Hầu hết các ứng dụng web đều có database để backup và để không bị ảnh hưởng khi tắt server, v.v. Cần phân biệt 2 loại database chính trong trường hợp này:
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;Application database&lt;/em&gt; : dùng cho trường hợp có nhiều giao dịch được cập nhật, loại này còn có tên gọi là &lt;em&gt;OLTP&lt;/em&gt; (online transaction processing)&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Analytical database&lt;/em&gt;: được xây dựng cho việc phân tích dữ liệu còn gọi là &lt;em&gt;OLAP&lt;/em&gt; (online analytical processing)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-trích-xuất-dữ-liệu-từ-database-như-thế-nào&quot;&gt;2. Trích xuất dữ liệu từ database như thế nào?&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Dùng URI/chuỗi connection, cú pháp như sau:
    &lt;pre&gt;&lt;code&gt;[database_type]://[user[:password]@][host][:port]
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;Trong Python, ta dùng connection URI thông qua package &lt;code&gt;sqlalchemy&lt;/code&gt; để tạo &lt;em&gt;database engine&lt;/em&gt; :&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;img/create-engine.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Từ engine đã được tạo ra, ta có thể dùng nó để đặt vào 1 số package hỗ trợ nó tương tác với database, đặc biệt là package &lt;code&gt;pandas&lt;/code&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;import requests
```&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;lấy-dữ-liệu-từ-bài-viết-của-hackernews-về-f12-inspect-để-lấy-url-của-nó&quot;&gt;Lấy dữ liệu từ bài viết của Hackernews về, F12 inspect để lấy URL của nó&lt;/h1&gt;
&lt;p&gt;resp = requests.get(“https://hacker-news.firebaseio.com/v0/item/16222426.json”)&lt;/p&gt;

&lt;h1 id=&quot;in-dữ-liệu-vừa-parse-thành-file-json-ra-màn-hình&quot;&gt;in dữ liệu vừa parse thành file json ra màn hình&lt;/h1&gt;
&lt;p&gt;print(resp.json())&lt;/p&gt;

&lt;h1 id=&quot;parse-dữ-liệu-ra-rồi-gán-value-của-key-score-vào-biến-post_score-sau-đó-in-cái-biến-ra&quot;&gt;parse dữ liệu ra rồi gán value của key “score” vào biến post_score, sau đó in cái biến ra&lt;/h1&gt;
&lt;p&gt;post_score = resp.json()[“score”]
print(post_score)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;

* Một số ví dụ mở rộng hơn (xem phần 3 để hiểu hơn):

Đọc dữ liệu từ database của postgreSQL, hàm extract dùng SQL query có nhiệm vụ chuyển từ dữ liệu bảng thành kiểu object mà pandas dùng (là dataframe)

&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&quot;function-to-extract-table-to-a-pandas-dataframe&quot;&gt;Function to extract table to a pandas DataFrame&lt;/h1&gt;
&lt;p&gt;def extract_table_to_pandas(tablename, db_engine):
    query = “SELECT * FROM {}”.format(tablename)
    return pd.read_sql(query, db_engine)&lt;/p&gt;

&lt;h1 id=&quot;connect-to-the-database-using-the-connection-uri-sử-dụng-package-sqlalchemy&quot;&gt;Connect to the database using the connection URI, sử dụng package sqlalchemy&lt;/h1&gt;
&lt;p&gt;connection_uri = “postgresql://repl:password@localhost:5432/pagila” 
db_engine = sqlalchemy.create_engine(connection_uri)&lt;/p&gt;

&lt;h1 id=&quot;extract-the-film-table-into-a-pandas-dataframe-lưu-ý-nhớ-để-tên-bảng-dạng-chuỗi&quot;&gt;Extract the film table into a pandas DataFrame, lưu ý nhớ để tên bảng dạng chuỗi&lt;/h1&gt;
&lt;p&gt;extract_table_to_pandas(“film”, db_engine)&lt;/p&gt;

&lt;h1 id=&quot;extract-the-customer-table-into-a-pandas-dataframe&quot;&gt;Extract the customer table into a pandas DataFrame&lt;/h1&gt;
&lt;p&gt;extract_table_to_pandas(“customer”, db_engine)
```&lt;/p&gt;

&lt;h2 id=&quot;2-transform-data&quot;&gt;2. TRANSFORM DATA&lt;/h2&gt;
&lt;h3 id=&quot;1-một-số-phương-thức-chuyển-đổi-dữ-liệu&quot;&gt;1. Một số phương thức chuyển đổi dữ liệu&lt;/h3&gt;
&lt;p&gt;Có thể thực hiện 1 hoặc nhiều các hình thức trong giai đoạn chuyển đổi dữ liệu đã rút trích:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Select 1 hay nhiều cột&lt;/li&gt;
  &lt;li&gt;Phiên dịch dữ liệu thành code. Ví dụ như New York sẽ biến thành NY&lt;/li&gt;
  &lt;li&gt;Kiểm tra dữ liệu có đúng không, nếu dữ liệu không đúng với kiểu dữ liệu hoặc dữ liệu muốn nhận từ cột, ta có thể bỏ record đó đi. Ví dụ như cột ngày nhưng lại chứa giá trị khác ngày.&lt;/li&gt;
  &lt;li&gt;Tách dữ liệu của 1 cột thành nhiều cột&lt;/li&gt;
  &lt;li&gt;Join dữ liệu từ các nguồn, các bảng khác nhau.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-một-số-ví-dụ&quot;&gt;2. Một số ví dụ&lt;/h3&gt;

&lt;p&gt;Bạn có thể dùng package &lt;code&gt;pandas&lt;/code&gt; để chuyển đổi dữ liệu nếu lượng dữ liệu nhỏ. Ta có ví dụ tách dữ liệu từ 1 cột thành 2 cột sử dụng pandas:
&lt;img src=&quot;img/split-pandas.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Nếu dữ liệu lớn, thông thường người ta sẽ dùng &lt;strong&gt;PySpark&lt;/strong&gt;. Ta có ví dụ chuyển đổi dữ liệu bằng cách join các bảng với nhau. 
Nhưng trước hết chúng ta cần đẩy dữ liệu lên Spark:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/extract-pyspark.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;jbdc:&lt;/code&gt;để nhắn nhủ với Spark là phải dùng JBDC để kết nối, sau đó, ta input vào tên của bảng và cuối cùng trong &lt;code&gt;properties&lt;/code&gt; chúng ta đặt thông tin kết nối vào.&lt;/p&gt;

&lt;p&gt;Dưới đây là 2 bảng cần join với nhau thông qua &lt;code&gt;customer_id&lt;/code&gt; để tính rating trung bình của mỗi customer dành cho các phim:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/rating-join.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Và làm sao để dùng PySpark join và tính toán dữ liệu? Xem ảnh dưới nhé:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/join-pyspark.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Mình sẽ cho ra thêm các bài viết tìm hiểu sâu hơn về PySpark trong thời gian tới, các bạn hãy cùng chờ đợi nhé!&lt;/p&gt;

&lt;h2 id=&quot;iii-load-data&quot;&gt;III. LOAD DATA&lt;/h2&gt;

</description>
        <pubDate>Sat, 29 May 2021 00:00:00 +0700</pubDate>
        <link>http://localhost:5000/data-etl/</link>
        <guid isPermaLink="true">http://localhost:5000/data-etl/</guid>
        
        
        <category>Data</category>
        
      </item>
    
  </channel>
</rss>
