
var documents = [{
    "id": 0,
    "url": "/tuyen-nnt.github.io/404.html",
    "title": "404",
    "body": "404 Page not found!Please use the search bar from the bottom left or visit our homepage! "
    }, {
    "id": 1,
    "url": "/tuyen-nnt.github.io/about",
    "title": "Hello, My name is Tuyen (Marie Nguyen). Welcome to my page!",
    "body": "This website is a demonstration to see Memoirs Jekyll theme in action. The theme is compatible with Github pages, in fact even this demo itself is created with Github Pages and hosted with Github.  Get Memoirs for Jekyll → "
    }, {
    "id": 2,
    "url": "/tuyen-nnt.github.io/authors",
    "title": "Authors",
    "body": "{% for author in site. authors %}                       {% if author[1]. gravatar %}                {% else %}                {% endif %}                  {% if author[1]. web %}                       {% endif %}          {% if author[1]. twitter %}                      {% endif %}          {% if author[1]. email %}                      {% endif %}                                     {{ author[1]. display_name }}:         {{ author[1]. description }}                {% endfor %}"
    }, {
    "id": 3,
    "url": "/tuyen-nnt.github.io/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 4,
    "url": "/tuyen-nnt.github.io/contact",
    "title": "Contact",
    "body": "  Please send your message to {{site. name}}. We will reply as soon as possible!   "
    }, {
    "id": 5,
    "url": "/tuyen-nnt.github.io/",
    "title": "Home",
    "body": "  {% for post in paginator. posts %}    {% include postbox. html %}  {% endfor %}  {% include pagination. html %}"
    }, {
    "id": 6,
    "url": "/tuyen-nnt.github.io/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 7,
    "url": "/tuyen-nnt.github.io/page2/",
    "title": "Home",
    "body": "  {% for post in paginator. posts %}    {% include postbox. html %}  {% endfor %}  {% include pagination. html %}"
    }, {
    "id": 8,
    "url": "/tuyen-nnt.github.io/page3/",
    "title": "Home",
    "body": "  {% for post in paginator. posts %}    {% include postbox. html %}  {% endfor %}  {% include pagination. html %}"
    }, {
    "id": 9,
    "url": "/tuyen-nnt.github.io/Jekyll-install/",
    "title": "Setup Jekyll themes",
    "body": "2021/08/10 - Fork Jekyll theme &amp; Play: Đây là theme blog mình đang sử dụng: https://github. com/tuyen-nnt/jekyll-theme-memoirs Các bước build Jekyll cho blog này: https://bootstrapstarter. com/jekyll-theme-memoirs/(Tìm hiểu thêm tại: https://jekyllrb. com/docs/)  B1: git clone https://github. com/wowthemesnet/jekyll-theme-memoirs. git B2: Tải Ruby https://www. ruby-lang. org/en/documentation/installation/ B3: cd vào thư mục theme rồi gem install bundler B4: bundle installKết quả build thành công:  B5: Sửa lại _config. yml theo blog của mình B6: bundle exec jekyll serve --watch B7: Xem web blog tại http://127. 0. 0. 1:4000/jekyll-theme-memoirs (nếu folder vẫn giữ tên cũ) B8: Thêm blogs định dạng . md vào folder _posts. Trước mỗi bài viết sẽ có ô YAML là định dạng chung, bạn chỉ cần điền vào thông tin của mình là được (nhưng vẫn giữ form nhé). Chi tiết xem link các bước thực hiện. Tìm hiểu về Bundler install: https://bundler. io/ Tìm hiểu về Gemfile: https://bundler. io/gemfile. html "
    }, {
    "id": 10,
    "url": "/tuyen-nnt.github.io/python-intermediate/",
    "title": "Python - Part 2",
    "body": "2021/08/02 - 1. Dictionaries: Là tập hợp các cặp key:value khi cần kết nối dữ liệu với nhau như 1 table để tra cứu nhanh và có thể chỉ ra unique keys khi tra cứu, thay vì nối 2 list lại để lấy index rồi tra cứu value.    So sánh giữa list và dict:     Cú pháp tạo dict như sau:  my_dict = {	key:value,	key:value}    Access dict như sau:my_dict['key'] =&gt; cho ra value của key đó.     Thêm key:value vào dict:world[ sealand ] = 0. 25     Check xem dict đã được thêm key ở trên vào chưa: sealand in world =&gt; trả về True/False. Với ‘seadland’ là key và word là tên dict.     Cập nhật lại giá trị cho key sealand:world['sealand'] = 0. 28Vì key trong dict là unique nên Python hiểu là bạn muốn thay đổi giá trị chứ không phải tạo mới cặp key:value.     Xóa cặp key:value:del(world['sealand'])     Dict trong dict:Cũng như list có thể chứa list trong list. Xem ví dụ:   # Dictionary of dictionarieseurope = { 'spain': { 'capital':'madrid', 'population':46. 77 },     'france': { 'capital':'paris', 'population':66. 03 },     'germany': { 'capital':'berlin', 'population':80. 62 },     'norway': { 'capital':'oslo', 'population':5. 084 } }  Để access giá trị của dict, ta sẽ dùng dấu [] như trong array:  europe['spain']['population'] =&gt; Vậy để add thêm cặp key:dict vào trong dict trên thì làm thế nào? # Create sub-dictionary datadata = {  'capital':'rome',  'population':59. 83}# Add data to europe under key 'italy'europe['italy'] = dataTa chỉ cần tách ra tạo dict phụ trước và gán nó vào biến lưu object value. Sau đó ta thêm cặp key:value vào dict như bình thường. Lưu ý:  Keys không được trùng nhau trong 1 dict, vì nếu trùng, nó sẽ chỉ lấy giá trị cuối cùng.  Keys phải là immutable object (không đổi), còn list thì mutable nên list cũng không được là key trong dict. 2. Pandas: Tabular dataset trong Pythonrow = observations column = variable  Để làm việc với dạng data này thì cần cấu trúc dạng chữ nhật. =&gt; 2D Numpy array =&gt; Nhưng với các dữ liệu có nhiều thông tin với nhiều datatype khác nhau như str, float,… thì Numpy chưa hiệu quả. Vậy nên pandas package chính là solution và quen thuộc trong Data science.  Nó được build dựa trên Numpy.  Là tool ở cấp độ cao trong thao tác với dữ liệu.  Pandas lưu dữ liệu bảng trong object gọi là Dataframe. Cách tạo dataframe từ dictionary: import pandas as pdbrics = pd. DataFrame(dict) Để tạo index cho observations trong df, ta dùng attribute index và gán 1 list với thứ tự chính xác các index mong muốn: brics. index = [. . . ,. . . ] CSV fileNhưng thực tế trong Data science, ta phải đối mặt với lượng data khổng lồ tùy trường hợp cụ thể, nên thông thường ta không tự tạo dataframe. Giả sử các data đến từ file có . csv viết tắt của comma separated values.  Để import vào môi trường Python ta dùng cú pháp:brics = pd. read_csv( path/to/brics. csv ) Tuy nhiên đối với file có index, khi import vào thì cột index đầu tiên sẽ bị ngầm hiểu là cột đầu của dữ liệu chính. Để tránh điều này, ta phải thêm argument index_col=0, kết quả:  Để thay đổi index tự động từ 0-n bằng label được định nghĩa trong 1 list tạo riêng tự chọn, ta dùng cú pháp:```  Definition of row_labels  row_labels = [‘US’, ‘AUS’, ‘JPN’, ‘IN’, ‘RU’, ‘MOR’, ‘EG’]  Specify row labels of carscars. index = row_labels ##### Cách để access DataframeTa input vào label hoặc index của column hoặc row. Ví dụ cụ thể ta có df là cars, xem cú pháp dưới đây: * Access COLUMN (cột):	* Dùng [] : 	- Nếu muốn output là Series object: ``cars['country', . . . ]``	- Nếu muốn output là Dataframe, dùng double ngoặc vuông:``cars[['country', . . . ]]``&gt; Nhìn ở góc khác, ta đang input vào ngoặc vuông 1 list chứa column labels. 	* Dùng ``loc`` (chọn 1 phần data dựa trên label-based) hoặc ``iloc`` (chọn data dựa trên integer position-based)	- cars. loc['country', . . . ] hoặc cars. loc[['country', . . . ]] 	- car. iloc[0, . . . , . . . ] hoặc car. iloc[[0, . . . , . . . ]]	* Access ROW (quan sát)		* Chỉ có cách là dùng [] nhưng input vào số:	- Nếu muốn lấy row từ index 1 đến 3:``cars[1:4]`` 	* Dùng loc hoặc iloc và input vào index của row thay vì tên cột như truy cập vào column. * Access ROWs &amp; COLUMNs bất kì:	* Sử dụng loc và iloc tiện lợi:	- Ta chỉ cần đặt vào label của row và column trong loc hoặc iloc theo thứ tự ``row, column``. 	- Nếu chọn nhiều hơn 1 label trong row hoặc column, ta biến argument row hoặc column thành list. Xem	 hình ví dụ:	![](img/loc-iloc. png)	&gt; Nhận xét: - Dấu ngoặc vuông``[]`` có giới hạn chức năng và lý tưởng nhất là sử dụng trong 2D Numpy array để access value dễ dàng nhất. 	- Nếu muốn dấu``[]``có thể mở rộng khả năng access value trong pandas như dấu``[]``trong 2D Numpy array, thì ta cần sử dụng ``loc`` và ``iloc``. ![](img/iloc-loc. png)		##### Filter dataframe* Bước 1: Access cột trả về series object. * Bước 2: Xác định điều kiện filter và trả về Boolean Series. Nếu &gt; 2 điều kiện thì phải sử dụng Numpy variants của toán tử and, or, not. * Bước 3: Dùng Boolean Series là kết quả của bước 1 làm input trong dấu ngoặc vuông của Dataframe. Kết quả trả về các record thỏa điều kiện. &gt; You'll want to build up a boolean Series, that you can then use to subset the cars DataFrame to select certain observations. If you want to do this in a one-liner, that's perfectly fine!#### 3. LOOP##### WHILE##### FOR for var in seq :	expression Trong đó ``var`` là biến bất kỳ có thể đặt tên sao cũng được. Python dùng nó để quét lần lượt cái phần tử trong ``seq``. FOR còn dùng để lặp từng char trong string. ![](img/string-loop. png)* enumerate() : cung cấp 2 giá trị cho mỗi lần lặp gồm ``index`` và ``value (giá trị)``. ![](img/enumerate-for. png)Mỗi data structure sẽ có cách loop các nhau và cách định nghĩa sequence khác nhau (seq). Cụ thể các bạn xem dưới đây nhé:##### Loop với List của Lists * Nếu list mà bạn cần lặp là list của list, thì dùng cách như sau:house list of listshouse = [[“hallway”, 11. 25],     [“kitchen”, 18. 0],     [“living room”, 20. 0],     [“bedroom”, 10. 75],     [“bathroom”, 9. 50]] Build a for loop from scratchx quét từng list trong list, dùng [] để truy cập phần tử của sub-listfor x in house :  print(“the “ + x[0] + “ is “ + str(x[1]) + “ sqm”)``` Loop với DictionarySử dụng method items() : for key, val in my_dict. items() : Loop với Numpy arraySử dụng function np. nditer(my_array) đặc biệt là với 2D array. for val in np. nditer(my_array) :    Với 1D array ta có thể sử dụng loop thông thường, nhưng với 2D thì nó sẽ in ra 2D array thay vì ra các giá trị cần lấy trong loop.     Dùng nditer sẽ giúp in ra từng giá trị từ trái sang phải từ trên xuống dưới của 2D array.  Pandas DataFrameiterrows() : Trong mỗi lần lặp, method này sẽ generate ra 2 giá trị:  Label của row (nếu ko có thì là index tự động) Data của row (là Pandas Series có index/label là tên cột - còn gọi là fieldname) Để loop in ra giá trị của cột mong muốn cho mỗi lần lặp, ta chỉ cần: print(row[“tên cột”])  Thêm cột vào Dataframe bằng loop:Ví dụ ta muốn thêm cột tính độ dài của cột “country”:brics. loc[lab,  tên cột mới ] = len(row[ country ])  Nhận xét: Cách này tốt trong trường hợp ít record. Vì ta đang tạo ra Series object cho mỗi vòng lặp và nó sẽ không hiệu quả với các dataset khổng lồ, thậm chí gây ra vấn đề khi xử lý dữ liệu. Vậy nên, cách tốt nhất là ta sử dụng function apply(tên function) cho mỗi cột mà ta muốn tính toán rồi gán vào cột mới trong dataframe: brics[ cột mới ] = brics[ country ]. apply(len)  Cách hoạt động: Function apply() sẽ gọi function len() mà mỗi giá trị của cột country sẽ là input để tính độ dài từng country. Kết quả trả về là 1 array mà chúng ta có thể dễ dàng lưu thành cột mới trong Dataframe. "
    }, {
    "id": 11,
    "url": "/tuyen-nnt.github.io/import-data-medium/",
    "title": "Import Data - Part 2",
    "body": "2021/07/18 - 1. Import + Load + Tạo HTTP/GET REQUEST:  Lưu file mềm xuống local:urlretrieve(url, 'filename. csv')Trước tiên phải from urllib. request import urlretrieve  Mở và đọc file mềm trên web:df = pd. read_csv(url, sep=';')   Show các dòng đầu tiên của df:print(df. head())   URL (Uniform/Universal Resource Locator)phần lớn là các địa chỉ web, ngoài ra còn là FTP (file transfer protocol)URL gồm 2 phần:  Protocol Identifier : http hoặc https   Tên resource: datacamp. com=&gt; tạo thành 1 địa chỉ web     HTTP (HyperText Transfer Protocol)Là protocol ứng dụng cho các hệ thống thông tin phân tán, cộng tác và siêu phương tiện, nền tảng giao tiếp dữ liệu cho WWW. HTTPS - có độ an toàn bảo mật cao hơn HTTP   Mỗi khi truy cập vào 1 trang web nghĩa là bạn đang gửi 1 HTTP request cho 1 server. Request này được gọi là GET request, đây là loại request phổ biến nhất.  urlretrieve : gửi GET request và lưu dữ liệu xuống local máy  HTML (HyperText Markup Language)2. Các cách gửi GET request::  Cách 1: sử dụng urllib. request=&gt; from urllib. request import urlopen, RequestMột số functions của package urllib. request  request = Request(url) : đóng gói GET request response = urlopen(request) : gửi request và catch phản hồi =&gt; trả về HTTP response object có tích hợp method read() và close() html = response. read() : trả về HTML định dạng string   response. close(): dùng xong nhớ đóng lại   Cách 2: rất phổ biến, sử dụng package requestsCho phép gửi HTTP request có tổ chức mà ko cần làm thủ công requests. get(url) : sau khi import package requests, hàm request. get() sẽ đóng gói request thông qua url, gửi request đi và nhận lại phản hồi và lưu vào biến r.  Ở đây hàm request. get() sẽ làm nhiệm vụ của Request(url) và urlopen(request đã đóng gói)của cách 1 r. text : r là biến lưu response của hàm trên, sử dụng method . text cho response để chuyển HTML của url sang dạng string. 3. Scraping web trong Python: HTML là sự kết hợp của data có cấu trúc và không cấu trúc.  Hàm BeautifulSoup() có tác dụng parse và trích xuất data từ HTML, và làm cho các tag được biểu diễn đẹp hơn. Cách sử dụng: from bs4 import BeautifulSoup Sau khi gửi nhận phản hồi của GET request, ta được file html như trên. Sau đó, ta dùng hàm BeautifulSoup để extract các data có cấu trúc của file html, lưu kết quả là một object vào một biến mới. Kết quả của hàm BeautifulSoupcó tích hợp hàm . prettify() để làm đẹp kết quả. soup = BeautifulSoup(html_doc)print(soup. prettify())    Các hàm khác có thể dùng sau khi parse và nhận kết quả từ BeautifulSoup:      soup. title() : trích title của file html   soup. get_text(): trích tất cả text của file html   soup. find_all() : tìm tất cả các data theo điều kiện hoặc tag nào đó.  Ví dụ:     for link in soup. find_all('a'): print(link. get('href')    hoặc      for link in a_tags: print(link. get('href'))      =&gt; Ở đây, ta sử dụng vòng lặp for kết hợp hàm . find_all() extract data nằm trong tag &lt;a&gt; của file html và in ra từng link của mỗi dòng tìm được, ta cũng có thể lưu soup. find_all() vào một biến nào đó. Hàm link. get('href') dùng để extract giá trị link của attribute href trong tag &lt;a&gt; 4. Load và khám phá file JSON: FIle JSON nằm ở local Bước 1: Tạo connection với file JSON trong local và load file  with open( tên file. json ) as json_file : json_data = json. load(json_file)  Ở đây json_data là 1 object dictionary, ta check bằng type(json_data) ra kết quả dict   Bước 2: Sử dụng vòng lặp for để in cặp key-value ra  for k in json_data. keys(): print(k + ': ', json_data[k])  Từ object dictionary trên, ta dùng àm . keys để truy cập vào keys của file và dùng cú pháp dictionary[key] để truy cập vào value.  5. APIs và tương tác cơ bản: API là gì? Là một bộ protocols và routines để xây dựng và tương tác với phần mềm Một tập hợp code cho phép 02 chương trình phần mềm giao tiếp với nhauVí dụ nếu muốn stream data của Twitter thì ta cùng API của Twitter.  Thông thường data thường được lấy về từ APIs ở định dạng JSON. URL có gì và làm thể nào để nó biết pull data từ API về?url = 'http://www. omdbapi. com/?t=hackers'  http - dấu hiệu là ta đang tạo 1 HTTP request www. omdbapi. com - nghĩa là ta đang query OMDB API ?t=hackers     Đây gọi là Query String   Không có quy ước và không buộc có trong đường dẫn   Sau dấu ? là phần query. Theo document trên trang chủ OMDB API thì có nghĩ là ta đang muốn trả về data của bộ phim có title (t) ‘Hackers’. Cụ thể xem phần Usage + Parameters.    # Import packageimport requests# Assign URL to variable: urlurl = 'https://en. wikipedia. org/w/api. php?action=query&amp;prop=extracts&amp;format=json&amp;exintro=&amp;titles=pizza'# Package the request, send the request and catch the response: rr = requests. get(url)# Decode the JSON data into a dictionary: json_datajson_data = r. json()print(json_data)# Print the Wikipedia page extractpizza_extract = json_data['query']['pages']['24768']['extract']print(pizza_extract)Ở 2 dòng code cuối, để biết tại sao code như thế, ta truy cập url trên browser, nó sẽ hiện ra các tab. Ta muốn extract data từ api của url thì ta mở từ tab query &gt; pages &gt; 24768 &gt; extract thì sẽ nhận được data từ api đó. Load và khám phá Twitter data# Import packageimport json# String of path to file: tweets_data_pathtweets_data_path = 'tweets. txt'# Initialize empty list to store tweets: tweets_datatweets_data = []# Open connection to filetweets_file = open(tweets_data_path,  r )# Read in tweets and store in list: tweets_datafor line in tweets_file:  tweet = json. loads(line)  tweets_data. append(tweet)# Close connection to filetweets_file. close()# Print the keys of the first tweet dictprint(tweets_data[0]. keys()) Đầu tiên ta gán đường dẫn tên file chứa Twitter data ở local máy vào 1 biến.  Tiếp theo ta tạo 1 mảng rỗng để chứa mỗi dòng tweet là 1 phần tử trong mảng.  Sau đó ta mở connection đến file local đó thông qua dường dẫn tweets_data_path và lưu vào tweets_file.  Tiếp theo ta dùng vòng lặp for để đọc từng dòng của tweets_file:     Dùng hàm json. load(line) để load từng dòng lưu vào biến tweet, để dùng hàm trên phải import json package         Note: mỗi lần load line để lưu vào tweet là một dictionary.           Sử dụng biến mảng tweets_data kết hợp hàm append(tweet) để add thêm phần tử dictionary mới (hay còn gọi là tweet) vào mảng.    In ra tất cả các keys của phần tử đầu tiên (tweet hay dict) của mảng.    Đưa mảng vào Dataframe sử dụng package pandas để phân tích# Import packageimport pandas as pd# Build DataFrame of tweet texts and languagesdf = pd. DataFrame(tweets_data, columns=['text','lang']) # Print head of DataFrameprint(df. head()) Hàm pd. Dataframe() cần 2 tham số là data và column để xây dựng df     Tham số đầu có thể là mảng, dict hoặc dataframe   Tham số thứ 2 là column label, nếu không có label thì dùng RangeIndex(0,1,2,…n). Nếu có label trong data như ví dụ trên, ta chỉ cần columns=['text','lang'] để chọn label cho column muốn rút giá trị. Ở ví dụ trên ta sẽ tạo 2 cột text và lang.    Streaming# Initialize Stream listenerl = MyStreamListener()# Create your Stream object with authenticationstream = tweepy. Stream(auth, l)# Filter Twitter Streams to capture data by the keywords:stream. filter(track=['clinton', 'trump', 'sanders', 'cruz'])   Class MyStreamListener() được khai báo sẵn tại đây: https://gist. github. com/hugobowne/18f1c0c0709ed1a52dc5bcd462ac69f4     Ta tạo object streambằng cách đưa vào hàm tweepy. Stream() athentication handler auth và object l - stream listener trên.     Object stream có tích hợp hàm . filter(), trong hàm này có attribute track=[] là list chứa các keyword mà ban muốn filter.  Phân tích data cơ bảnimport redef word_in_text(word, text):  word = word. lower()  text = text. lower()  match = re. search(word, text)  if match:    return True  return False Ở trên ta có hàm word_in_text() để đếm số lượng tweet chứa keyword. Nhưng ở đây chúng ta chưa đếm, mà chỉ đưa kết quả nếu True sẽ +1 vào biến đếm ở bước tiếp theo. # Initialize list to store tweet counts[clinton, trump, sanders, cruz] = [0, 0, 0, 0]# Iterate through df, counting the number of tweets in which# each candidate is mentionedfor index, row in df. iterrows():  clinton += word_in_text('clinton', row['text'])  trump += word_in_text('trump', row['text'])  sanders += word_in_text('sanders', row['text'])  cruz += word_in_text('cruz', row['text']) Tiếp theo ta sẽ tạo list trong Python, mỗi item sẽ có giá trị đếm bắt đầu =0. Mục đích ở đây là để đếm số tweet count được cho mỗi keyword.  Sử dụng vòng lặp để đi từng row và check, nếu gặp keyword sẽ +1 vào biến đếm. Nếu True (nghĩa là có keyword đó) thì += 1. Basic Data visualization# Import packagesimport seaborn as snsimport matplotlib. pyplot as plt# Set seaborn stylesns. set(color_codes=True)# Create a list of labels:cdcd = ['clinton', 'trump', 'sanders', 'cruz']# Plot the bar chartax = sns. barplot(cd, [clinton, trump, sanders, cruz])ax. set(ylabel= count )plt. show() Đầu tiên cần import 2 package như trên để vẽ biểu đồ Hàm sns. barplot() có 2 tham số:     Tham số đầu: list label cần biểu diễn giá trị   Tham số thứ 2: list chứa giá trị của các label cần biểu diễn. List này đã được khởi tạo và đếm ở code trước đó.    "
    }, {
    "id": 12,
    "url": "/tuyen-nnt.github.io/python-basic/",
    "title": "Python - Part 1",
    "body": "2021/07/11 - I. LIST:  Thêm phần tử cho list:Chỉ cần + [list] x = [ a ,  b ,  c ,  d ]y = x + [ e ,  f ] Xóa phần tử list:Dùng del(phần tử). Lưu ý là khi xóa thì các phần tử ở sau bị đẩy index lên. x = [ a ,  b ,  c ,  d ]del(x[1]) Dấu [index:index] trong list     x[start:end] Với start là chỉ số lấy end chỉ số không lấyVí dụ:   x[2:5] : lấy giá trị của index từ 2 đến 4   x[:3] : từ đầu đến index 2   x[3:] : từ index 3 đến hết   x[:] : lấy hết phần tử    Dấu ;:Dùng để tách command code trên cùng 1 dòng, nếu khác dòng thì không cần. ```  Same line  command1; command2  Separate linescommand1command2 * Copy list:Khi copy kiểu ``x=y`` thì thực tế ta đang copy địa chỉ list của y cho x. Nghĩa là khi ta thay đổi phần tử trong x thì y cũng thay đổi theo. Để xử lý tình huống này, nếu chỉ muốn copy giá trị list thì ta dùng: ``x = list(y)`` hoặc ``x = y[:]``* Convert datatypex = str(y)x = int(y)x = float(y)&gt; Check datatype bằng function ``type()``* Xem cấu trúc của 1 function có sẵn:``help(max)`` hoặc ``?max``#### II. METHOD* Cũng là function nhưng dành cho từng type* Tất cả mọi thứ trong Python đều là object. * Object có các method riêng, phụ thuộc vào data type #### III. NumpyTại sao dùng Numpy?* Rất quyền lực, có thể sử dụng cho nhiều data type khác nhau. Tuy nhiên mỗi tập hợp (array) chỉ được chứa 1 loại data type. * Có thể thêm, xóa, sửa* Quan trọng trong Data Science	* Làm các phép toán cho các tập hợp	* Tốc độ nhanh* Ta thấy nếu áp dụng phép toán như -*/ trên kiểu dữ liệu list thì sẽ throw Error ``không hỗ trợ``. Nếu + thì sẽ ghép 2 list lại thành 1 list. &gt; Tuy nhiên, ta đang cần +-*/ trên 2 list theo index tương ứng. Thì Numpy sẽ giúp ta giải quyết khó khăn này. Giải pháp Numpy có gì?* Python kiểu số. Có hàm ``np. mean()`` và ``np. median()`` rất phổ biến trong data science. * Thay thế cho Python List : kiểu dữ liệu ``Numpy Array``* Giúp tính toán trên toàn bộ array* Nhanh và dễ dàng* Cài đặt trong terminal: ``pip3 install numpy``Như vậy, để thực hiện các phép toán trên list, ta phải chuyển nó sang kiểu dữ liệu Numpy Array như sau:import numpy as npnp_height = np. array(height)np_weight = np. array(weight)bmi = np_weight / np_height ** 2 **Lưu ý quan trọng:*** Mỗi array chỉ được chứa 1 loại data type. * Type khác nhau thì hành vi của nó sẽ khác nhau. VD: 	* Phép + 2 list thì là ghép 2 list thành 1. 	* Phép + 2 array thì là cộng theo giá trị index tương ứng của 2 array với nhau. ##### 1. Numpy Subsetting * Ta có array ``bmi``. * Để truy cập vào array ta dùng cú pháp: ``bmi[index]``* Để xét các giá trị trong array có thỏa điều kiện không, ta dùng: ``bmi &gt; 23``&gt; Trả về array có kiểu Boolean (True/False)* Để trả về array chứa các giá trị thỏa điều kiện, ta dùng: ``bmi[bmi &gt; 23]`` ##### 2. Type của Numpy arrayNếu ``print(type(np_height))``&gt; numpy. ndarrayVới numpy là package, n là layer của array. ndarray là kiểu dữ liệu chỉ sử dụng trong Numpy. ##### 3. 2D Numpy Arrays Cách tạo 2D array bằng 2 array:* array1* array2* meas = np. array([array1, array2])Có thể xem 2D numpy array như phiên bản nâng cấp của  list của list  vì ta có thể thực hiện các phép toán với nó. Để tạo array 2D, ta chỉ cần input các giá trị vào như dưới đây, input 1 list có 2 sub-list vào argument của method ``np. array`` theo cấu trúc hình chữ nhật:![](img/2d-array. png)Mỗi sub-list là một row của array.  Nếu ta thay đổi kiểu dữ liệu của bất kỳ giá trị nào trong array sang kiểu khác như từ float sang string, thì mặc nhiên numpy sẽ chuyển tất cả các giá trị còn lại sang string (in ra sẽ thấy). &gt; Vì mỗi numpy array chỉ chứa 1 kiểu dữ liệu. Để biết cấu trúc data của array như thế nào, ta dùng attribute ``shape`` của array:![](img/array-shape. png) *Vì là attribute nên nó không có ``()`` như method~*Có 2 cú pháp để truy cập giá trị:![](img/2d-subset. png)* Cách 1: np_2d[row][column]* Cách 2: np_2d[row,column]* Dấu ``:`` vẫn sẽ được sử dụng giống như 1D array ở trên nếu muốn chọn cụ thể vùng giá trị muốn lấy. *Với row, column là index, chú ý ở đây vẫn sử dụng zero-index cho 2D array. *##### 4. Toán tử Boolean trong NumpyVới Numpy array ta có thể sử dụng phép so sánh như các ví dụ trên, nhưng nếu sử dụng kết hợp and, or, not thì sẽ throw Error. Do vậy, ta phải sử dụng:* np. logical_and()* np. logical_or() * np. logical_not()Ex:np. logical_and(my_house &gt; 13,        your_house &lt; 15) Kết quả trả về 1 Boolean Series, thích hợp dùng để filter dataframe```Với my_house và your_house là 2 Numpy array. "
    }, {
    "id": 13,
    "url": "/tuyen-nnt.github.io/spark/",
    "title": "(ENG) The basics of Spark",
    "body": "2021/06/27 - Deciding whether or not Spark is the best solution for your problem takes some experience, but you can consider questions like: Is my data too big to work with on a single machine?Can my calculations be easily parallelized?Bước 1: Create an instance of the SparkContext class to connect to a Spark cluster from PySpark. You may also find that running simpler computations might take longer than expected. That’s because all the optimizations that Spark has under its hood are designed for complicated operations with big data sets. That means that for simple or small problems Spark may actually perform worse than some other solutions! Verify SparkContextprint(sc) Print Spark versionprint(sc. version) &lt;SparkContext master=local[*] appName=pyspark-shell&gt;2. 3. 1 Using DataFrames Spark’s core data structure is the Resilient Distributed Dataset (RDD). This is a low level object that lets Spark work its magic by splitting data across multiple nodes in the cluster. However, RDDs are hard to work with directly, so in this course you’ll be using the Spark DataFrame abstraction built on top of RDDs. The Spark DataFrame was designed to behave a lot like a SQL table (a table with variables in the columns and observations in the rows). Not only are they easier to understand, DataFrames are also more optimized for complicated operations than RDDs. When you start modifying and combining columns and rows of data, there are many ways to arrive at the same result, but some often take much longer than others. When using RDDs, it’s up to the data scientist to figure out the right way to optimize the query, but the DataFrame implementation has much of this optimization built in! To start working with Spark DataFrames, you first have to create a SparkSession object from your SparkContext. You can think of the SparkContext as your connection to the cluster and the SparkSession as your interface with that connection. I. SELECT  Loai 2     flights. select(flights. air_time/60)    returns a column of flight durations in hours instead of minutes. if you wanted to . select() the column duration_hrs (which isn’t in your DataFrame) you could do  flights. select((flights. air_time/60). alias(“duration_hrs”)) The equivalent Spark DataFrame method . selectExpr() takes SQL expressions as a string:  flights. selectExpr(“air_time/60 as duration_hrs”)with the SQL as keyword being equivalent to the . alias() method. To select multiple columns, you can pass multiple strings. "
    }, {
    "id": 14,
    "url": "/tuyen-nnt.github.io/data-visualization/",
    "title": "Data Visualization",
    "body": "2021/06/23 - 1. Các loại chart cơ bản: BAR CHART &amp; COLUMN CHART  Giúp ta nhìn vào giá trị cụ thể cho mỗi loại Có 4 loại:  Stacked bar và column chart     Biểu đồ chồng nhau theo giá trị,     Clustered bar và column chart     Biểu đồ nhiều cột trong 1 phân loại     100% stacked bar và column chart     Biểu đồ chồng theo %     Combo chart     Biểu đồ kết hợp cột và biểu đồ đường    LINE CHART  Giúp biểu diễn chuỗi giá trị theo dạng có hình, thường là thông qua diễn tiến thay đổi của thời gian AREA CHART  Dựa trên Line chart nhưng được fill màu PIE CHART &amp; DONUT CHART  Biểu diễn mỗi quan hệ giữa các thành phần và tổng thể TREE MAP  Biểu diễn mỗi quan hệ giữa các thành phần và tổng thể, với các hình vuông có màu có kích cỡ riêng biểu thị phần mà các giá trị chiếm. CARD &amp; MULTI-ROW CARD  Card     biểu diễn 1 giá trị    *Multi-row card  dùng để biểu diễn nhiều giá trị GAUGE CHART &amp; KPI  được thiết kế để hiển thị dữ liệu thực tế so sánh với dữ liệu ngân sách/doanh thu hoặc mục tiêu đã lên kế hoạch. TABLE &amp; MATRIX  biểu diễn chi tiết dữ liệu văn bản bằng định dạng Bảng  Table:     chứa dữ liệu liên quan trong chuỗi logical của dòng và cột, có thể bao gồm header &amp; footer của bảng     Matrix:     giống như bảng nhưng matrix có thể thu lại hoặc mở rộng ra bằng dòng hoặc cột    HIERARCHIES:  Level data từ cao đến thấp Ví dụ:Year =&gt; Quarter =&gt; Month =&gt; DayCompany =&gt; Region =&gt; Country =&gt; DIvision =&gt; Unit HÀM:  Là các công thức được định nghĩa trước sẵn để biểu diễn các phép tính trên các giá trị gọi là tham trị arguments. 2. Kiến thức nền tảng để visualize data: Có 3 cách để lấy được insight của data:    Cách 1: Tính toán thống kêmean (trung bình), median(trung vị), standard deviation (phương sai)     Cách 2: Run model/Chạy mô hìnhLinear (Tuyến tính) hoặc hồi quy logistic     Cách 3: Vẽ plotscatter, bar, histogram (biểu đồ tần suất),…Scatter plot:  The Datasaurus Dozen  Có 13 datasets, mỗi Dataset có 2 trục x và y được gọi là variable Variable đơn giản chỉ là biệt ngữ thống kê để chỉ cột dữ liệu Khi tính phương sai của mỗi dataset, ta sẽ tính ra 2 phương sai cho x và y trên tất cả các record. Vì dataset trên có 2 giá trị x và y.  Phương sai dùng để tính toán sự biến thiên của dữ liệu. Chọn biểu đồ chấm plot loại gì thì phù hợp?Trước tiên phải xác định variable x và y của data thuộc loại nào. Có 3 loại:    Continuous : thường là số và có thể làm các phép toán cho nó. Ví dụ như nhiệt độ, chiều cao, doanh thu,…     Categorical : thường là dạng văn bản text, những thứ được phân loại hay mô tả. Ví dụ như màu mắt, quốc gia,…     Cả hai loại trênVí dụ như tuổi thì dạng continuous, còn nhóm tuổi từ 25-30 thì lại là categorical. Thời gian thì continuous còn tháng thì categorical.      Ở đây tùy vào mục đích visualization mà bạn sẽ quyết định nó thuộc loại nào cho phù hợp.    Khi nào nên dùng biểu đồ tần suất Histogram? Nếu bạn có biến continuous như trên Khi bạn muốn biết hình dạng của sự phân tán data, ví dụ như bạn muốn biểu đồ thể hiện rõ giá trị cao nhất và thấp nhất. Một số thuật ngữ:  Bin (interval) : khoảng cách các ô trục trên biểu đồ, ví dụ 0-5, 5-10,… Nếu muốn rõ data hơn thì ta co bin lại 0-1, 1-2,…Như hình, bin 10-15 tuổi có giá trị trục y là 4, nghĩa là có 4 người từ 10-15 tuổi. Sự lựa chọn binwidth sẽ ảnh hưởng lớn đến hình ảnh biểu đồ. Dưới đây cho thấy nếu thu nhỏ bin lại còn 1 năm tuổi thì nhìn rất lộn xộn.  Các tiêu chí trải nghiệm qua để chọn binwidth phù hợp:    Modality : có bao nhiêu đỉnh trong biểu đồ?Unimodal, bimodal hay trimodal?     Skewness: lệch lạc hay cân xứng?lệch trái, phải hay cân đối ở giữa?     Kurtosis: có bao nhiêu điểm có giá trị = 0? (extreme value)  Khi nào nên vẽ Box Plots? Khi chúng ta có 1 variable là continuous, được tách ra phân loại bởi 1 variable categorical.  Khi chúng ta muốn so sánh sự phân tán dữ liệu của variable continuous cho mỗi category (phân loại). Các chỉ số trên box plots:  lower quartile: 1/4 có giá trị dưới số này median : trung vị upper quartile: 1/4 có giá trị trên số này inter-quartile range: khoảng cách từ lower đến upper whiskers: đường thẳng ngang hai bên, đường kẻ ra gấp 1-1,5 lần inter-quarter, dài đến mức độ đủ để biết rằng ngoài đường kẻ thì không có giá trị nào cả (extreme value).  Phân loại nào chỉ có đường thẳng nghĩa là chỉ có 1 giá trị. "
    }, {
    "id": 15,
    "url": "/tuyen-nnt.github.io/phpmyadmin/",
    "title": "Set-up phpMyAdmin",
    "body": "2021/06/15 -    Initial setup with Ubuntu 20. 4: https://www. digitalocean. com/community/tutorials/initial-server-setup-with-ubuntu-20-04     Install Mysql on Ubuntu 20. 4:https://www. digitalocean. com/community/tutorials/how-to-install-mysql-on-ubuntu-20-04     Install LAMP (Linux, Apache, MySQL, PHP)https://www. digitalocean. com/community/tutorials/how-to-install-linux-apache-mysql-php-lamp-stack-on-ubuntu-20-04     Install and Secure phpMyAdmin:https://www. digitalocean. com/community/tutorials/how-to-install-and-secure-phpmyadmin-on-ubuntu-20-04     Secure Apache with Let’s Encrypt on Ubuntu 20. 04 (free TLS/SSL certificate)https://www. digitalocean. com/community/tutorials/how-to-secure-apache-with-let-s-encrypt-on-ubuntu-20-04     DOCKER COMPOSE &amp; NETWORKhttps://vsudo. net/blog/docker-toan-tap. html  CÓ 2 CÁCH ĐỂ SỬ DỤNG phpMyAdmin:C1: cài đặt thủ công và sử dụng trên localhost hoặc domain trên server mình host (xem link trên)https://www. digitalocean. com/community/tutorials/how-to-install-and-secure-phpmyadmin-on-ubuntu-20-04 =&gt; đã thử và okC2:dùng Docker network chứa 2 container là MySQL và phpMyAdmin để truy cập MySQL server trên phpMyAdmin hosthttps://vsudo. net/blog/docker-toan-tap. html =&gt; đã thử và ok Cách để đưa db của mình chạy trên container có sẵn của phpMyAdminB1: tạo image chạy trên base php cho file . php chứa truy vấn bảng của db (như 1 ứng dụng) và phải cài đặt biến môi trường trong này cho giống với config của container. B2: compose với container của phpMyAdmin có sẵn (có thể chọn các image phù hợp nhu cầu) và bổ sung image ở trên vào file docker-compose. yml --------------------------------------------------WORKDIR /var/www/tuyen. techCOPY /etc/apache2/sites-available/tuyen. tech. conf /etc/apache2/sites-available/COPY /etc/apache2/conf-available/phpmyadmin. conf /etc/apache2/conf-available/COPY /usr/share/phpmyadmin/. htaccess /usr/share/phpmyadmin/COPY . /var/www/tuyen. tech/RUN sudo apt update &amp;&amp; apt install -y \&amp;&amp; apache2 \&amp;&amp; php libapache2-mod-php php-mysql \&amp;&amp; mysql-server \&amp;&amp; phpmyadmin php-mbstring php-zip php-gd php-json php-curl \&amp;&amp; phpmyadmin RUN sudo mysql_secure_installation \&amp;&amp; sudo mysql \&amp;&amp; sudo phpenmod mbstring \&amp;&amp; sudo htpasswd -c /etc/phpmyadmin/. htpasswd tuyen \&amp;&amp; sudo systemctl restart apache2 EXPOSE 9090--------------------------FROM ubuntu:latestMAINTAINER tuyennnt &lt;tuyendev96@gmail. com&gt;WORKDIR /var/www/tuyen. techCOPY /etc/apache2/sites-available/tuyen. tech. conf /etc/apache2/sites-available/COPY /etc/apache2/conf-available/phpmyadmin. conf /etc/apache2/conf-available/COPY /usr/share/phpmyadmin/. htaccess /usr/share/phpmyadmin/COPY . /var/www/tuyen. tech/RUN sudo apt update &amp;&amp; apt install -y \&amp;&amp; apache2 \&amp;&amp; php libapache2-mod-php php-mysql \&amp;&amp; mysql-server \&amp;&amp; phpmyadmin php-mbstring php-zip php-gd php-json php-curl \&amp;&amp; phpmyadmin RUN sudo mysql_secure_installation \&amp;&amp; sudo mysql \&amp;&amp; sudo phpenmod mbstring \&amp;&amp; sudo htpasswd -c /etc/phpmyadmin/. htpasswd tuyen \&amp;&amp; sudo systemctl restart apache2 EXPOSE 9090: : "
    }, {
    "id": 16,
    "url": "/tuyen-nnt.github.io/data-etl/",
    "title": "Extract - Transform - Load (ETL process)",
    "body": "2021/05/29 - Tìm hiểu về ETLI. EXTRACT DATA: 1. Các cách để trích xuất dữ liệu: Có 3 cách:    Trích xuất từ file text, như file . txt or . csvText file có 3 loại là : 	* Text thuần	* Flat file (là file có . tsv hoặc . csv cách nhau bởi dấu “,” hoặc “tab” giữa các giá trị). Những file này có dòng thể hiện các record và cột thể hiện attribute của record. 	*File JSON: bán cấu trúc, có 4 kiểu dữ liệu atomic là number, string, boolean và null và 2 kiểu dữ liệu dạng composite là array và object. 	JSON có package hỗ trợ là “json” để import data	     Trích xuất từ web hoặc APIs của web services, như là Hacker News API      Thông qua web:      Ví dụ: bạn tìm kiếm thông tin trên google. com thì trình duyệt của bạn sẽ gửi request của bạn đến server của google và google sẽ trả về dữ liệu mà bạn đang tìm kiếm. * Thông qua API của web:Không phải lúc nào các trang web cũng trả về kết quả mà người thường có thể đọc ngay, mà các trang web đó sẽ trả về định dạng JSON thông qua API mà chúng ta request. Ta xem ví dụ request API từ trang Hackernews:Ta import package “request” rồi dùng method . get() để chèn vào link web cần lấy file JSON. Sau đó ta dùng method . json() để phân tích file JSON từ kết quả đã lấy được và chuyển hóa nó thành Python object.  Trích xuất từ một database trên web services Hầu hết các ứng dụng web đều có database để backup và để không bị ảnh hưởng khi tắt server, v. v. Cần phân biệt 2 loại database chính trong trường hợp này:     Application database : dùng cho trường hợp có nhiều giao dịch được cập nhật, loại này còn có tên gọi là OLTP (online transaction processing)   Analytical database: được xây dựng cho việc phân tích dữ liệu còn gọi là OLAP (online analytical processing)   2. Trích xuất dữ liệu từ database như thế nào?:  Dùng URI/chuỗi connection, cú pháp như sau:  [database_type]://[user[:password]@][host][:port]  Trong Python, ta dùng connection URI thông qua package sqlalchemy để tạo database engine : Từ engine đã được tạo ra, ta có thể dùng nó để đặt vào 1 số package hỗ trợ nó tương tác với database, đặc biệt là package pandas.  import requests```Lấy dữ liệu từ bài viết của Hackernews về, F12 inspect để lấy URL của nóresp = requests. get(“https://hacker-news. firebaseio. com/v0/item/16222426. json”) in dữ liệu vừa parse thành file json ra màn hìnhprint(resp. json()) parse dữ liệu ra rồi gán value của key “score” vào biến post_score, sau đó in cái biến rapost_score = resp. json()[“score”]print(post_score) * Một số ví dụ mở rộng hơn (xem phần 3 để hiểu hơn):Đọc dữ liệu từ database của postgreSQL, hàm extract dùng SQL query có nhiệm vụ chuyển từ dữ liệu bảng thành kiểu object mà pandas dùng (là dataframe)Function to extract table to a pandas DataFramedef extract_table_to_pandas(tablename, db_engine):  query = “SELECT * FROM {}”. format(tablename)  return pd. read_sql(query, db_engine) Connect to the database using the connection URI, sử dụng package sqlalchemyconnection_uri = “postgresql://repl:password@localhost:5432/pagila” db_engine = sqlalchemy. create_engine(connection_uri) Extract the film table into a pandas DataFrame, lưu ý nhớ để tên bảng dạng chuỗiextract_table_to_pandas(“film”, db_engine) Extract the customer table into a pandas DataFrameextract_table_to_pandas(“customer”, db_engine)``` 2. TRANSFORM DATA: 1. Một số phương thức chuyển đổi dữ liệu: Có thể thực hiện 1 hoặc nhiều các hình thức trong giai đoạn chuyển đổi dữ liệu đã rút trích:  Select 1 hay nhiều cột Phiên dịch dữ liệu thành code. Ví dụ như New York sẽ biến thành NY Kiểm tra dữ liệu có đúng không, nếu dữ liệu không đúng với kiểu dữ liệu hoặc dữ liệu muốn nhận từ cột, ta có thể bỏ record đó đi. Ví dụ như cột ngày nhưng lại chứa giá trị khác ngày.  Tách dữ liệu của 1 cột thành nhiều cột Join dữ liệu từ các nguồn, các bảng khác nhau. 2. Một số ví dụ: Bạn có thể dùng package pandas để chuyển đổi dữ liệu nếu lượng dữ liệu nhỏ. Ta có ví dụ tách dữ liệu từ 1 cột thành 2 cột sử dụng pandas: Nếu dữ liệu lớn, thông thường người ta sẽ dùng PySpark. Ta có ví dụ chuyển đổi dữ liệu bằng cách join các bảng với nhau. Nhưng trước hết chúng ta cần đẩy dữ liệu lên Spark: jbdc:để nhắn nhủ với Spark là phải dùng JBDC để kết nối, sau đó, ta input vào tên của bảng và cuối cùng trong properties chúng ta đặt thông tin kết nối vào. Dưới đây là 2 bảng cần join với nhau thông qua customer_id để tính rating trung bình của mỗi customer dành cho các phim: Và làm sao để dùng PySpark join và tính toán dữ liệu? Xem ảnh dưới nhé: Mình sẽ cho ra thêm các bài viết tìm hiểu sâu hơn về PySpark trong thời gian tới, các bạn hãy cùng chờ đợi nhé! III. LOAD DATA: "
    }, {
    "id": 17,
    "url": "/tuyen-nnt.github.io/react-native-css/",
    "title": "React Native - CSS rules",
    "body": "2021/05/24 - Phân biệt các attribute quan trọng sau để build giao diện trong react native:  flexDirection: “row” hoặc “column” justify-content : “center”main/primary axis phụ thuộc vào flexDirection, ta có space-evenly   align-items : “center”căn chỉnh secondary axis cho mỗi line, có các loại như center, baseline,…   flexWrap: “wrap” để các component ko bị chèn ép mất đi   align-Content : căn chỉnh toàn bộ nội dung của 1 block trên secondary axis, chỉ hoạt động khi có flexWrap.   align-self flex: 1 flexBasis: 100, //width (nếu main là row) or height, phụ thuộc vào primary axis (main) flexGrow: 1 //giống flex : 1, trải ra đầy màn hình   flexShrink: 1 //giống flex : -1, co lại để ko tràn màn hình     bottom, right, left, top : di chuyển qua trái, phải bao nhiêu pixel   position: “absolute” hoặc “relative” //giá trị mặc định trong react native là “relative”*Dimensions: import thư viện này trong react DIP công thức như sau: Physical Pixels = DIPs x Scale Factor vd điện thoại có scale là 2 và point điểm ảnh là 320x480 thì View đối với Width có giá trị 150 là 150x2=300 =&gt; nghĩa là bề ngang là 1/2 màn hình "
    }, {
    "id": 18,
    "url": "/tuyen-nnt.github.io/docker/",
    "title": "Basics of Docker",
    "body": "2021/05/02 - Cách RUN UBUNTU: docker run ubuntu //nếu chưa pull ubuntu image về thì sẽ pull rồi start, còn nếu pull rồi thì nó sẽ start container này luôn =&gt; nếu khi start mà thấy chưa có interact gì thì nó sẽ stop container lại luôn docker ps //xem list các tiến trình đang chạy của container hoặc các container đang chạy docker ps -a //xem các container đã dừng lại docker run -it ubuntu // start container với interaction mode và load ubuntu image lên trong cái container này Các câu lệnh: history !2 //để output cmd thứ 2 trong list history ls -1 //líst ds theo dạng dọc ls -l //list ds chi tiet touch &lt;tên file&gt; //lệnh tạo file mkdir &lt;tên thư mục&gt; //lệnh tạo thư mục mv &lt;tên file hoặc địa chỉ&gt; &lt;tên file hoặc địa chỉ&gt; //đổi tên hoặc di chuyển cat &lt;tên file&gt; more &lt;tên file hoặc địa chỉ&gt; //xem nội dung theo từng page, bấm phím space để qua trang tiếp theo nhưng ko scroll up lên được, nhấn enter để chạy từng line để xem less &lt;tên file hoặc địa chỉ&gt; // cat &lt;tên file&gt; &gt; &lt;tên file khác&gt;//copy nội dung file này vào file khác cat &lt;tên file&gt; &lt;tên file khác&gt; &gt; &lt;tên combined file&gt;	//combine nội dung 2 file vào file khác dấu &gt; áp dụng cho hầu hết các câu lệnhvd: echo hello &gt; hello. txtls -l /etc &gt; hello. txtsẽ cho kết quả ra file hello. txt trên. Trong Linux, mọi thứ đều ở duới dangj file, từ process, devices, hoặc địa chỉ thư mục đều là files Cấu trúc Linux:  / bin: chưa các file binaries, chương trình boot: các file liên quan booting dev: devices etc: editable text configuration, chứa file config home: thư mục của user root: chỉ có root mới vào được thư mục này lib: libary files như software library dependencies var: như biến, chứa các file được update thường xuyên như log,… proc: chứa các tiến trình đang runningCác bước để sử dụng Docker:  Cài đặt Docker Tạo 1 program và Tạo file plain text Dockerfile ghi hướng dẫn để đưa cho docker đóng gói ứng dụng thành 1 image. Image chứa tất cả mọi thứ để chương trình chạy. IMAGE bao gồm:     A cut-down OS   Môi trường runtime (vd như Node, Python)   File ứng dụng   Thư viện thứ 3   Biến môi trường =&gt; Sau khi có cái Image này, ta sẽ nói với Docker để start container Container như 1 process, nhưng là process đăc biệt vì nó có file system được cung cấp bởi Image. Ứng dụng của chúng ta sẽ được chạy trong cái process/container này.    Ok giờ chúng ta start docker. Thay vì chạy ứng dụng như bình thường, ta gọi Docker để chạy bên trong cái container nhé docker run . . Ví dụ sự khác nhau : Để chạy 1 chương trình JS đơn giản, ta cần phải qua 4 bước:  Start OS Cài Node Copy file ứng dụng Chạy node app. jsVới docker, ta chỉ cần:    Bước 1:   Vào thư mục project trên vscode code .  Tạo file Dockerfile không ext, và input các thông tin sau: ``` FROM node:alpine     chọn image node trên trang docker hub và : distribution của linux, ở đây chọn alpine vì nó nhẹ nhất COPY . /app copy tất cả file execute vào thư mục app tạo mới, vào rồi copy vào trong imagehoặc có thể hiểu là trong cái image có file system, và chúng ta tạo thư mục app bên trong file system đó, trong thư mục app chứa tất cả các file của program WORKDIR /apptạo đường dẫn rút gọn CMD node /app. jscâu lệnh chạy ứng dụng, để docker biết mà chạy câu nào khi run     Bước 2: TA nói docker đóng gói úng dụng thành image docker build -t hello-docker . trong đó, dấu . chỉ cho docker biết chỗ nào chứa Dockerfile hello-docker là tên repos docker mình tự tạo để quản lýĐể xem có bao nhiêu docker đang chạy: docker image ls kết quả câu lệnh có cột SIZE chỉ size của OS (alpine) + ứng dụng + node  BƯớc 3: Chạy thử docker image docker run hello-docker ta có thể chạy ở thư mục nào cũng được, vì image đã chứa mọi thứ cần*BƯớc 4 Publish lên docker hub hub. docker. com KHi ở máy khác, ta muốn pull image về chạy:  BƯớc 1: Kiểm tra version docker, nếu chưa download thì chạy lệnh install docker vesion*Bước 2: Kéo image về docker pull senrie/hello-docker Kiểm tra lại = cách: docker image ls *Bước 3: Chạy chương trình trên machine docker run senrie/hello-docker "
    }, {
    "id": 19,
    "url": "/tuyen-nnt.github.io/import-begin/",
    "title": "Import Data - Part 1",
    "body": "2021/04/10 - 1. Flat file:  Là file text thông thường chứa các record tổ hợp bởi các trường hoặc attribute (thuộc tính) và mỗi trường chứa nhiều nhất 1 thông tin.  Flat file chứa các row và mỗi row là 1 record.  Flat file chỉ dùng để chứa dữ liệu của 1 bảng tính.  Nó không có relationships như relational database Rất phổ biến trong data scienceCác loại flat file:  . csv . txt Có dấu phân cách , hoặc tab2. Các cách import Flat file: Có 2 loại package chính để import, tùy trường hợp sử dụng:  NumPy : nếu dữ liệu column cơ bản là số, vì:     Nó là lưu dữ liệu số dạng mảng một cách hiệu quả và nhanh   Nó cần thiết cho các package khác như scikit-learn sử dụng trong Machine-learning.    Nó có nhiều hàm hỗ trợ để dễ dàng import các mảng data số như loadtxt() và genfromtxt().     pandas : nếu dữ liệu column là cả số lẫn string, dataframe là dtype sinh ra để lưu dạng hỗn hợp này. Import flat file bằng NumPy# Import packageimport numpy as np# Assign filename to variable: filefile = 'digits. csv'# Load file as array: digitsdigits = np. loadtxt(file, delimiter=',')# Print datatype of digitsprint(type(digits)) Hàm np. loadtxt()tạo object numpy dạng mảng, cần 2 tham số là:     Tên file   Dấu phân cách    Chúng ta có thể tùy chỉnh bằng cách thêm các tham số khác vì NumPy có nhiều sự lựa chọn:```  Import numpy  import numpy as np  Assign the filename: filefile = ‘digits_header. txt’ Load the data: datadata = np. loadtxt(file, delimiter=’\t’, skiprows=1, usecols=[0,2]) Print dataprint(data) * Các tham số ở trên bao gồm:	* ``skiprows= n`` : không lấy data của n dòng đầu tiên để đưa vào mảng, vì có thể đó là header hoặc các record mà ta không muốn lấy. 	* ``usecols=[]`` : tùy chọn những cột mà ta muốn lấy giá trị cách nhau bởi dấu phẩy, index côt bắt đầu từ 0 đến n-1 (với n là số côt). 	* ``print(array_object)`` : dùng để in object mảng ra console. 		Assign filename: filefile = ‘seaslug. txt’ Import file: datadata = np. loadtxt(file, delimiter=’\t’, dtype=str) Print the first element of dataprint(data[0]) Import data as floats and skip the first row: data_floatdata_float = np. loadtxt(file, delimiter=’\t’, dtype=float, skiprows=1) Print the 10th element of data_floatprint(data_float[9]) * Trong trường hợp set data của bạn có chứa các value với kiểu dữ liêu khác nhau ví dụ như giá trị dòng đầu tiên là header chứa string data. Có 2 cách để xử lý:	* *Cách 1*: Thêm tham số ``dtype=str`` để tất cả các giá trị khi import vào đều là string, và không bị báo lỗi ``ValueError``. 	* *Cách 2*: dùng tham số ``skiprows=n``, với n là số row sẽ skip từ row đầu tiên. Cách này nếu chúng ta biết được row nào có chứa giá trị khác các giá trị còn lại mà gây ra ``ValueError``. 	Plot a scatterplot of the dataplt. scatter(data_float[:, 0], data_float[:, 1])plt. xlabel(‘time (min. )’)plt. ylabel(‘percentage of larvae’)plt. show() * Sau khi có mảng data ta có thể tùy biến thành biểu đồ như mã code trên. #### 3. Import các loại file khác##### Excel spreadsheetsImport pandasimport pandas as pd Assign spreadsheet filename: filefile = ‘battledeath. xlsx’ Load spreadsheet: xlsxls = pd. ExcelFile(file) Print sheet namesprint(xls. sheet_names) * Lưu ý ở đây biến``xls`` mới chỉ là object Excel do pandas định nghĩa, chưa phải là dataframe. Vì excel có nhiều sheet nhưng 1 dataframe chỉ có thể là 1 sheet. Nên ta sẽ xử lý ở bước sau. * Hàm ``. sheet_names`` in ra tên tất cả các sheet trong bảng tính. Load a sheet into a DataFrame by name: df1df1 = xls. parse(‘2004’) Print the head of the DataFrame df1print(df1. head()) Load a sheet into a DataFrame by index: df2df2 = xls. parse(0) Print the head of the DataFrame df2print(df2. head()) * Hàm ``. parse()`` sẽ giúp rút trích df (sheet) của excel file và cần ta đưa vào tham số là tên của sheet hoặc chỉ số từ 0-(n-1), với n là số lượng sheet để load dataframe. ##### Pickled file (chuỗi byte hay bytestream =&gt; native trong Python)* Thực tế có những dạng datatype như dictionary hay list không có cách nào rõ ràng đưa vào lưu trong flat file như các datatype numpy. array hay pandas. dataframe. Do đó, pickle file ra đời. Đây là loại file dùng ngôn ngữ native mà con người đọc không hiểu. Nếu như bạn chỉ muốn import data thì chỉ cần *serialize* datatype dict hay list,. . . bằng cách convert nó sang dạng bytestream để trở thành pickled file. * Ở bài này, chúng ta chưa nói đến cách convert, mà sẽ học cách mở file pickled đã được convert sẵn và lưu ở local thay vì mở flat file như đã học trước đó. &gt; Có thể hiểu pickled file là file hỗ trợ bạn lưu dữ liệu có datatype kiểu dictionary, list,. . . ##### SAS7BDAT file ``. sas``SAS là viết tắt của Statistical Analysis System, dùng trong BA, BI, tính toán phân tích data hay thống kê về sinh học,. . . Import sas7bdat packagefrom sas7bdat import SAS7BDAT Save file to a DataFrame: df_saswith SAS7BDAT(‘sales. sas7bdat’) as file:  df_sas = file. to_data_frame() Print head of DataFrameprint(df_sas. head()) Plot histogram of DataFrame features (pandas and pyplot already imported)pd. DataFrame. hist(df_sas[[‘P’]])plt. ylabel(‘count’)plt. show() ##### Stata file ``. dta``Là sự kết hợp giữa statistics + data, dùng trong các nghiên cứu học thuật data về dịch tễ hay khoa học xã hội. import pandas as pddf = pd. read_stata(‘disarea. dta’) ##### HDF5Là loại file dùng để lưu trữ lượng data số lớn lên đến hàng trăm GBs hay TBs, thậm chí có thể scale lên ExabytesImport packagesimport numpy as npimport h5py Assign filename: filefile = ‘LIGO_data. hdf5’ Load file: datadata = h5py. File(file, ‘r’) Print the datatype of the loaded fileprint(type(data)) Print the keys of the filefor key in data. keys():  print(key) Get the HDF5 group: groupgroup = data[‘strain’] Check out keys of groupfor key in group. keys():  print(key) Set variable equal to time series data: strainstrain = data[‘strain’][‘Strain’]. value Set number of time points to sample: num_samplesnum_samples = 10000 Set time vectortime = np. arange(0, 1, 1/num_samples) Plot dataplt. plot(time, strain[:num_samples])plt. xlabel(‘GPS Time (s)’)plt. ylabel(‘strain’)plt. show()``` MATLAB . mateach row is an instance of entity type "
    }, {
    "id": 20,
    "url": "/tuyen-nnt.github.io/csdl/",
    "title": "The origin of Database",
    "body": "2021/04/01 - Đi từ các cấu trúc dữ liệu như Array, Linked list, B-tree,… =&gt; Các cấu trúc dl này chỉ lưu những con số, không lưu được 1 tập dữ liệu liên quan với nhau =&gt; để lưu trữ tập hợp thông tin, người ta tạo ra CSDL =&gt; Để thêm xóa sửa nhanh chóng, người ta lại tạo ra ngôn ngữ SQL để làm phương tiện truy vấn dữ liệu Trừu tượng hóa dữ liệu cho phép mô tả dữ liệu theo  Đối tượng Thuộc tính Liên kết"
    }, {
    "id": 21,
    "url": "/tuyen-nnt.github.io/ubuntu-basic/",
    "title": "Learn Linux commands on Ubuntu",
    "body": "2021/03/22 - Làm quen với Ubuntu1. Một số câu lệnh thường dùng: Part 1: Tải ứng dụng trên ubuntu: sudo apt-get install alacarte Uninstall ứng dụng: sudo apt-get remove alacarte Đổi tên file: mv [đường dẫn với tên cũ] [đường dẫn với tên mới] Ví dụ: Đổi tên tập tin test1. txt trong /root thành test. txt: mv /root/test1. txt /root/test. txtmv Di chuyển file:mv [đường dẫn nguồn] [đường dẫn đích] Ví dụ: Di chuyển và đổi tên tập tin *test1. txt trong /root sang /etc đổi tên thành test. txt: mv /root/test1. txt /etc/test. txt Mở file xem dùng lệnh:cat &lt;đường dẫn hoặc tên file trong thư mục hiện hành&gt; Edit file hoặc tạo file mới dùng lệnh:nano &lt;đường dẫn hoặc tên file trong thư mục hiện hành&gt; Tìm file trong thư mục hiện hành: find . [tên file]find . //list ra tất cả các file trong thư mụcCập nhật phiên bản, ví dụ npm 7. 13. 0: npm install -g npm@7. 13. 0 Mở OVPN: sudo openvpn --config Downloads/client. ovpn Mở ứng dụng sau khi cd vào folder chứa file thực thi, dùng lệnh sau để mở ứng dụng : . /datagrip. sh Tải Remarkable để viết markdown thông qua wget thay vì snap hoặc apt-get : wget https://remarkableapp. github. io/files/remarkable_1. 87_all. debsudo dpkg -i remarkable_1. 87_all. deb*Chạy đến đây nếu gặp lỗi  dpkg: dependency problems prevent configuration of remarkable  ta chạy câu lệnh*&gt; sudo apt-get install -fsudo apt-get install -fReset lai cau commit trước đó git reset --soft HEAD^^COveride commit đã push^C git push origin +masterPush lên brach master git push origin +master Part 2: update 23. 05. 2021: Xem lịch sử viết cmd:cat ~/. bash_history Giải nén với file taztar -xvzf . . .  Giải nén với file taz:tar -xvf . . .  Giải nén với file deb:sudo dpkg -i . . .  Để xem nó là dạng file gì :file . . . .  Xem là file hay thư mục và các quyền:ls -l Nếu cần quyền root để thực thi thì đổi sang quyền owner cho user sudo chown -R tuyen:tuyen . //thay đổi owner cho user, dấu  .   chỉ tất cả các file trong thư mục hiện hành, tuyen là user : tuyen là user groupchmod +x Để bổ sung cấu hình cho hệ thống: sudo nano hostsEx:# Một ứng dụng cần config&lt;ip&gt; www. XXX. com&lt;ip&gt; licxxxx. XXXX. comvoi ip la so dang XXX. X. X. X//Lưu ý dùng quyền sudo với những file của hệ thốngGiải nén file . deb dùng lệnh:sudo dpkg -i remarkable_1. 87_all. deb 2. Cài đặt server tải package apt-get về từ VN để nhanh hơn dùng mặc định của nước ngoài: cd /etc/aptlssudo cp sources. list sourceslist. bak//back-up filesudo sed -i 's/vn. archive. ubuntu. com/mirror. bizflycloud. vn/' sources. list//thay thế tất cả link /vn. archive. ubuntu. com = link mirror. bizflycloud. vn trong file sources. listcat sources. listsudo apt-get updatesudo rm sourceslist. bak 3. Compile ứng dụng từ source code thủ công: Đối với những ứng dụng dùng apt-get gặp vấn đề version hoặc không tương thích với máy, ta sẽ chuyển sang dùng cách này. Tuy nhiên cách này nếu may mắn sẽ compile nhanh, ngược lại có nhiều trường hợp thiếu thư viện khi . /configure dẫn đến mất nhiều thời gian. Đó là lí do nhiều người sẽ cài đặt Docker để compile từ source code nhanh =&gt; mình sẽ hướng dẫn ở phần sau.  B1: Download source code về từ git dùng git clonegit clone &lt;đường dẫn&gt; B2: cd vào thư mục ứng dụng B3: Cấu hình cho ứng dụng chạy trên máy bạn, ở bước này đòi hỏi sự kiên nhẫn để cài đặt thêm những thư viện cần, chú ý xem lỗi từ cmd để fix chính xác. . /configureKhi tải thêm thư viện thì cú pháp:  sudo apt-get install &lt;tên thư viện&gt;-dev//Lưu ý phải có -dev vì -dev là source code của mấy cái thư viện  B4: Compile từ source code thành file binary  make//Trong quá trình runtime nếu được yêu cầu tải thêm thư viện thì đuôi thư viện ko cần -dev nữa, vì các file config đã được compile ra binary hết rồi, ko còn là source code nữa =&gt; do vậy bỏ đuôi -dev để tương thích  B5: Install file binary vô hệ thống hay nói cách khác là chuyển những file đã được compile ở trên vô hệ thốngsudo make install4. Cách pin ứng dụng lên thanh dock ubuntu:  Bước 1: Tải file tar ứng dụng về và giải nén bằng lệnh tar -xvzf [tên_file] Bước 2: Tạo file tên ứng dụng có đuôi . desktop trong thư mục . local/share/applications, ví dụ webstorm. sh bằng lệnh nano [tên_file] Bước 3: Mở file . desktop và paste dòng sau:# https://askubuntu. com/questions/975178/duplicate-icons-in-the-dock-of-gnome-shell-ubuntu-17-10/9752 30#975230# https://askubuntu. com/questions/990833/cannot-add-custom-launcher-to-dock-add-to-favorites# dconf-editor[Desktop Entry]Type=ApplicationTerminal=falseIcon[en_US]=/home/quocbao/Tools/WebStorm-2019. 2/bin/webstorm. svgName[en_US]=WebStormExec=/home/quocbao/Tools/WebStorm-2019. 2/bin/webstorm. shName=WebStormIcon=/home/quocbao/Tools/WebStorm-2019. 2/bin/webstorm. svgStartupWMClass=jetbrains-webstormTrong đó: * Icon: chứa đường dẫn thư mục có hình ảnh biểu tượng cho ứng dụng* Name: tên của ứng dụng* StartupWMClass: được lấy bằng cách chạy câu lệnh *xprop WM_CLASS* và bấm vào ứng dụng để hiện mã trên Terminal sau đó copy vào.  Bước 4: Gõ câu lệnh  dconf-editor Cửa sổ dconf hiện lên, tại mục Customize value gõ tại vị trí mong muốn xuất hiện:  ‘tên_file. desktop’ Lưu ý: các tên file cách nhau bởi dấu phẩy Một số lưu ý trong lúc thực hiện::  Khi file . sh không có quyền thực thi (kiểm tra quyền bằng câu lệnh ls -l &lt;tên_file&gt;, dùng tên file nếu đang ở trong thư mục chứa file còn không dùng đường dẫn đến file), ta cần thêm quyền thực thi (quyền mở file) bằng cách gõ câu lệnh sau:chmod +x &lt;đường dẫn file&gt;Tìm hiểu thêm các quyền tại đâyTìm hiểu thêm các lệnh khác tại đây Các loại đường dẫn:  ~/ : thay cho home /thư mục/… : là đường dẫn tuyệt đối, phải tuyệt đối chính xác, không rút gọn thư mục/…/ : là đường dẫn tương đối, đôi khi không có đoạn thư mục đầu vì đã ở trong thư mục đó rồi, v. v . / : chỉ thư mục hiện hành, nhưng đôi khi có các câu lệnh như “git . / bấm tiếp tab” sẽ gợi ý ra các file có thể áp dụng, nếu “git” thôi thì sẽ được list ra các câu lệnh có thể dùng với git, ví dụ . /vscode. shCre:    Part 1:https://askubuntu. com/questions/975178/duplicate-icons-in-the-dock-of-gnome-shell-ubuntu-17-10/975230#975230https://askubuntu. com/questions/990833/cannot-add-custom-launcher-to-dock-add-to-favoriteshttps://vinasupport. com/chmod-la-gi-huong-dan-su-dung-lenh-chmod-tren-linux-unix/https://blogd. net/linux/lam-viec-voi-tap-tin-va-thu-muc-tren-linux/     Part 2:https://www. liquidweb. com/kb/how-to-install-software-from-source-on-ubuntu/https://help. ubuntu. com/community/CompilingEasyHowTohttps://help. ubuntu. com/community/CompilingEasyHowTo  "
    }, {
    "id": 22,
    "url": "/tuyen-nnt.github.io/data-toolbox/",
    "title": "Data Toolbox",
    "body": "2021/03/17 - Chapter 1 : Các công cụ làm việc trong mảng Data EngineeringI. Database: 1. Database là gì?: Database là tập hợp dữ liệu lớn được tổ chức đặc biệt để tìm kiếm và rút trích dữ liệu nhanh.  Các đặc điểm của nó:  Lưu trữ dữ liệu Tổ chức dữ liệu Rút trích/Tìm kiến dữ liệu thông qua DBMS2. Phân biệt dữ liệu có cấu trúc và dữ liệu không cấu trúc: Có cấu trúc:: Database có schema, ví dụ như các relational database Bán cấu trúc (semi-structured):: Ví dụ như file JSON { “key” : “value” }Không cấu trúc:: Không có schema, giống như các tập tin : videos, hình ảnh 3. Phân biệt SQL và NoSQL: SQL database có những đặc điểm sau::  Có các bảng để truy vấn Có Database schema (xác định sự liên hệ và thuộc tính của database) Có các Relational database (có quan hệ với nhau) Các hệ quản trị cơ sở dữ liệu phổ biến của ngôn ngữ này: MySQL, PostgreSQLNoSQL database có những đặc điểm sau::  Có các Non-relational database Thường gắn với các dữ liệu không có schema (unstructured), nhưng đôi khi có các dữ liệu có schema (structured) Lưu trữ các cặp key-value (e. g. dùng cho caching hoặc cấu hình phân tán “distributed configuration”) Những ứng dụng thường dùng NoSQL là những ứng dụng chứa cặp key-value như Redis hoặc MongoDB có model là document database. *Các giá trị trong document database thường là các object có cấu trúc hoặc bán cấu trúc, ví dụ như JSON object. 4. SQL: Tìm hiểu về Database chema: Database schema có vai trò gì?:  Có nhiệm vụ mô tả cấu trúc và các mối quan hệ của các bảng trong database thông qua SQL code và sơ đồ schema Star schema: Trong datawarehouse database, thường những schema chúng ta thấy là star schema có sơ đồ giống như hình ngôi sao. Fact table ở giữa và xung quanh là các Dimension tables, trong đó:  Fact table: là table chứa các dữ liệu xảy ra trên thế giới như product orders, v. v Dimension table: là các table mang thuộc tính để mô tả cho fact table như màu sắc, kích thước, v. vTìm hiểu thêm về Star chema tại đây Ví dụ thực tế:Giả sử ta có database mô tả cấu trúc dữ liệu cho hệ thống bán hàng ở 1 cửa hàng quần áo: Giả sử ta có bảng invoice lưu dữ liệu bán hàng (fact table) có các cột sau:       id (primary key)   created_date_time   items_id   payment_method   customer_id   card_id             123   12:00:00   12/12/2021   1   Bank   111   9116   Ta sẽ có các bảng dimension sau để bảng invoice liên kết mối quan hệ nhằm mô tả chi tiết các giao dịch invoice: Bảng Item       id   item_name   category   color   price         1   Quần đùi lửng   Quần   Đen   200000   Bảng Customer       id   name   birthday   card_id   is_valid   num_of_orders         111   Thanh Tuyền   09/XX/XXXX   9116   0   5   Bảng Card       id   customer_id   point   expired_date         9116   111   2100   31/12/2025   II. Parallel computing: Parallel computing là gì?: Trước tiên ta đi từ ý tưởng của việc tạo ra parallel computing.  Nó hình thành nên nền móng cho các công cụ xử lý data hiện đại (data processing tool) Tuy nhiên lí do quan trọng nhất phải nói đến là để tối ưu Bộ nhớ và hiệu năng xử lý dữ liệuCách thức hoạt động::  Chia task thành nhiều task phụ Phân tán task phụ trên một vài máy tính (thường là các commodity computer hoặc đã có sẵn để ít tốn phí thay vì sử dụng các siêu máy tính) Các máy tính làm việc song song với nhau trên các task phụ, do đó các task được hoàn thành nhanh hơnChúng ta hãy cùng xem ví dụ vận hành shop may đồ: Đặt mục tiêu may 100 cái áo, thì shop nhận thấy:  Nhân viên may giỏi nhất nhóm may 1 cái áo trong 20 phút =&gt; 12 cái áo trong 4 tiếng Những nhân viên khác thì may 1 cái áo trong 1 tiếngSau khi áp dụng mô hình parallel bằng cách:  Chia ra 4 chu kỳ Mỗi chu kì 25 cái áo và 4 nhân viên may làm việc song songThì ta thấy được nếu các nhân viên may có khả năng thấp hơn khi cùng làm việc song song với nhau thì sẽ làm được 16 cái áo trong 4 tiếng. Nói về thực tế máy tính, 4 nhân viên may có năng lực thấp hơn thì sẽ giống như là các máy tính có sẵn, ít tốn phí, thay vì ta phải thuê 1 nhân viên giỏi hay có thể nói là siêu máy tính thì chi phí sẽ cao hơn nhiều nhưng không chắc chắc hiệu quả bằng. Tóm lại, lợi ích của parallel computing:  Hiệu suất xử lý Bộ nhớ: chia dữ liệu thành các tập hợp con và đưa vào bộ nhớ của các máy tính khác nhau=&gt; mức chiếm dụng bộ nhớ tương đối nhỏ và dữ liệu được đưa vào trong bộ nhớ gần RAM nhẩtNhững rủi ro khi áp dụng: Overhead due to communication  Yêu cầu chưa đủ lớn để áp dụng Cần nhiều processing units hơn Đôi khi tách ra sẽ gặp vấn đề về program runtime, yêu cầu tốn nhiều thời gian để xử lý giao tiếp giữa các processes hơn so với không tách ra. Việc có nhiều chương trình hơn sẽ khiến thời gian contact switch giữa các chương trình nhiều hơn không phù hợp khi yêu cầu chưa đủ lớn. Xem hình bên dưới:Code Python để chia thành nhiều task phụ: Sử dụng API multiprocessing. Pool Sử dụng DASK framework để tránh viết API dưới hệ thống Một số ghi chú cho Parallel computing:    Không phải lúc nào cũng tăng thời gian xử lý công việc, do hiệu ứng của overhead communication ở phần contact switch giữa các ứng dụng.   GIúp tối ưu việc sử dụng bộ xử lý đa nhiệm (multiple processing unit)  Giúp tối ưu bộ nhớ giữa một số hệ thống Bài viết về Parallel computing đến đây là kết thúc, các bạn có thể xem qua 1 số đoạn code liên quan đến chủ đề này ở repo data-engineering của mình nhé! III. Parallel computation framework: 1. Hadoop: Hadoop là tập hợp các dự án open-source được maintain bởi Apache Software Foudation. Có 2 dự án phổ biến thường được nhắc đến là MapReduce và HDFS. a. Nói về HDFS: Đây là tên gọi của hệ thống phân tán tập tin (distributed file system). Cũng là các tập tin trong máy tính nhưng được điều đặc biệt là nó được phân tán trên nhiều máy tính khác nhau. HDFS là một phần thiết yếu trong Big data để lưu trữ dữ liệu lớn.  b. Nói về MapReduce: Đây là một trong các mô hình đầu tiên phổ biến trong việc xử lý Big data. Cách hoạt động của nó là chia task lớn thành nhiều task nhỏ rồi phân tán khối lượng dữ liệu và dữ liệu đến các đơn vị xử lý (processing unit). Tuy nhiên, MapReduce có một số khuyết điểm có thể kể đến như khó viết các job để chia task và phân tán chẳng hạn.  Chương trình phần mềm Hive và một só phần mềm khác ra đời để giải quyết khó khăn trên. Hive như là lớp vỏ trên cùng trong hệ sinh thái của Hadoop giúp các dữ liệu đến từ những nguồn khác nhau có thể truy vấn bằng cách sử dụng ngôn ngữ truy vấn có cấu trúc Hive SQL (HQL). Ví dụ đoạn truy vấn Hive SQL:  Nhận xét: trông chả khác câu lệnh SQL thông thường phải không ? ^^ Tuy nhiên sau tấm màn đó thì mọi thứ sẽ khác. Câu truy vấn trên sẽ chuyển đổi thành job có nhiệm vụ phân tán đến tập hợp các máy tính đấy (cluster). 2. Spark framework: Ngoài Hadoop, ta còn có Spark, cũng có nhiệm vụ phân tán các task xử lý dữ liệu giữa các cluster, ngày nay được sử dụng phổ biến hơn. Trong khi hệ thống Hadoop MapReduce cần ổ đĩa đắt tiền để ghi dữ liệu giữa các job, thì Spark lại sử dụng một cách tối ưu bộ nhớ xử lý tránh sử dụng ổ đĩa để ghi dữ liệu. Spark ra đời đã cho thấy những hạn chế của MapReduce, trong đó bao gồm việc MapReduce hạn chế tương tác của người dùng khi truy cập phân tích dữ liệu và mỗi bước build sẽ phải dựa trên bước trước đó. =&gt; không linh hoạt, khó tương tác hơn Spark. a. Kiến trúc của Spark: Dựa trên RDDs (Resilient distributed datasets) RDD là một loại cấu trúc dữ liệu có nhiệm vụ duy trì các dữ liệu được phân tán giữa nhiều node. Không giống với DataFrame, RDDs không có các cột. Về khái niệm thì có thể xem nó là một dãy các tuples, ví dụ về tuple “day”: day = ('monday', 'tuesday', 'wednesday' , 'thursday', 'friday', 'saturday' , 'sunday')Với các dữ liệu có cấu trúc RDD ta có thể thực thi 2 loại lệnh :  Chuyển đổi: dùng method . map() hoặc . filter() =&gt; output ra các dạng dữ liệu đã được chuyển đổi Hành động: dùng method . count() hoặc . first() =&gt; ra 1 output duy nhất (số, chữ, v. v)Spark framework có nhiều interface ứng với các ngôn ngữ lập trình, phổ biến nhất là PySpark dùng ngôn ngữ Python. Ngoài ra còn có các ngôn ngữ khác như Scala, R.  **PySpark dùng host dựa trên Dataframe trừu tượng, đó là lí do nếu chúng ta thường sử dụng thư viện pandas của dataframe sẽ dễ làm quen hơn vì hoạt động của PySpark sẽ tương tự thế.    Tóm lại là các công việc về parallel computing từ đơn giản đến phức tạp cứ để nhà Spark lo :smile: còn chaỵ như thế nào là tùy bạn.  Xem ví dụ về PySpark khi tính trung bình các vận động viên theo nhóm tuổi nhé: "
    }, {
    "id": 23,
    "url": "/tuyen-nnt.github.io/one-day-just-started-adventure/",
    "title": "One day we just started our adventure",
    "body": "2020/01/12 - The die cut has also been employed in the non-juvenile sphere as well, a recent example being Jonathan Safran Foer’s ambitious Tree of Codes. As for this particular rendition of Charles Perrault’s classic tale, the text and design is by Lydia Very (1823-1901), sister of Transcendentalist poet Jones Very. The gruesome ending of the original - which sees Little Red Riding Hood being gobbled up as well as her grandmother - is avoided here, the gore giving way to the less bloody aims of the morality tale, and the lesson that one should not disobey one’s mother.  It would seem the claim could also extend to die cut books in general, as we can’t find anything sooner, but do let us know in the comments if you have further light to shed on this! Such books are, of course, still popular in children’s publishing today, though the die cutting is not now limited to mere outlines, as evidenced in a beautiful 2014 version of the same Little Red Riding Hood story. The first mass-produced book to deviate from a rectilinear format, at least in the United States, is thought to be this 1863 edition of Red Riding Hood, cut into the shape of the protagonist herself with the troublesome wolf curled at her feet. Produced by the Boston-based publisher Louis Prang, this is the first in their “Doll Series”, a set of five “die-cut” books, known also as shape books — the other titles being Robinson Crusoe, Goody Two-Shoes (also written by Red Riding Hood author Lydia Very), Cinderella, and King Winter. An 1868 Prang catalogue would later claim that such “books in the shape of a regular paper Doll… originated with us”. "
    }, {
    "id": 24,
    "url": "/tuyen-nnt.github.io/git-commit/",
    "title": "How to write effective git-commit?",
    "body": "2019/07/31 - Mẹo viết commit message hữu ích khi dùng gitGit là một hệ thống quản lý phiên bản phân tán phổ biến với mục đích theo dõi sự thay đổi của các tập tin trên máy tính và phối hợp công việc nhóm trên những tập tin này. Là một lập trình viên thì một trong những công cụ cơ bản mà chúng tôi không thể bỏ qua chính là việc sử dụng git trong quy trình làm việc. Sau đây là một trong những sai lầm mà dân lập trình hay mắc phải, về mặt kỹ thuật thì không hẳn nhưng chúng ta hãy tự hỏi rằng “Nếu bạn có thể làm tốt hơn thì tại sao không làm?” Một số quy tắc nên ghi nhớ khi viết commit message :    Tách dòng chủ đề ra khỏi phần thân bằng một dòng trống     Giới hạn dòng chủ đề tối đa 50 kí tự     Viết hoa dòng chủ đề     Sử dụng câu mệnh lệnh ở dòng chủ đề     Không kết thúc dòng chủ đề bằng dấu chấm     Gói gọn phần thân tối đa 72 kí tự     Sử dụng phần thân để giải thích “Cái gì”, “Tại sao” với “Như thế nào”  Sai lầm #1:: Chúng ta có khuynh hướng trộn lẫn chủ đề với phần thân của một commit message : Cách viết phần chủ đề chung với phần thân của thông điệp là một cách làm sai. Khi bạn nhận thấy commit message quá dài để giải thích thì có nghĩa là commit đang thực hiện quá nhiều thứ sẽ phá vỡ nó đi. Bạn viết:  git commit –m “added new css styling for danger button in order to differentiate between the primary button and other button styles. ” Thay vì nên viết:  git commit –m “Add new feature” Sai lầm #2:: Không giới hạn chủ đề tối đa 50 kí tự, phần thân của commit message tối đa 72 kí tự: Luôn đảm bảo chủ đề của commit không bao giờ vượt quá 50 kí tự và đây là qui tắc ngón tay cái. Thêm nhiều hơn số kí tự nên có sẽ có khuynh hướng sẽ bị Github cắt bớt đi, và vì những gì chúng ta đang cố gắng truyền tải là để một user nào đó trong nháy mắt biết được một commit đang làm gì. Một vài commit message yêu cầu giải thích nhiều hơn đặc biệt là khi dòng chủ đề có nội dung mơ hồ, do đó thêm nội dung phần thân sẽ hữu ích trong những trường hợp này. Luôn cố gắng giới hạn số lượng kí tự phần thân tối đa 72 kí tự, và hãy để phần thân giải thích những gì commit đang thực hiện và tại sao lại làm như vậy. Sai lầm #3:: Không viết hoa cho chủ đề của commit Bạn viết:  git commit –m “added new feature” Thay vì nên viết:  git commit –m “Add new feature” Sai lầm #4:: Kết thúc dòng chủ đề bằng dấu chấm Bạn viết:  git commit –m “Modified codebase. ”Thay vì nên viết: git commit –m “Modify codebase” Sai lầm #5:: Không sử dụng câu mệnh lệnh ở dòng chủ đề: Mọi git commit đúng chuẩn nên đặt ở dạng mệnh lệnh. “Đơn giản điều này có nghĩa là câu được viết theo dạng một hành động”. Một dòng chủ đề git commit thích hợp nên hoàn thành đúng cấu trúc cho câu sau đây:  If applied, this commit will “your subject line here” Ví dụ:  If applied, this commit will “Add auth to X” Từ đó, ta nhận thấy sẽ không đúng với những dạng không mệnh lệnh:  If applied, this commit will “added auth to Y” Sai lầm #6:: Phần thân giải thích Cái gì, Tại sao với Như thế nào: Như đã giải thích ở số #2 trên, luôn đảm bảo phần thân của commit giải thích chính xác cái gì và tại sao commit đó đang thực hiện. Giải thích tại sao sự thay đổi đó là cần thiết, và khía cạnh khác mà nó mang lại. Thay vì miêu tả cách mà bạn giải quyết vấn đề trên. Một số câu nói vui về git:  Why did the commit cross the rebase? To git to the other repoTạm dịch là: Sao commit qua được rebase? Vì ta git đến repo khác :v  In case of fire: git commit, git push, leave the buildingTạm dịch là: Khi gặp cháy thì phải git commit, git push, rồi mới rời khỏi tòa nhà :v Cre: https://code. likeagirl. io/useful-tips-for-writing-better-git-commit-messages-808770609503?fbclid=IwAR16siuZjdzxxQ4z9gz89BST5DPxINisBxzxVB-emDa-tuLl26KdkV15vsI Bài viết về git commit đến đây là hết rồi, mời các bạn xem thêm các bài viết khác nhé ! Tuyen Nguyen "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><span class='body'>"+ body +"</span><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-primary btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><small><span class='body'>"+ body +"</span><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});